[2025-12-02 22:47:51] ================================================================================
[2025-12-02 22:47:51] Starting OPTIMIZED fine-tuning with PlantNet weights
[2025-12-02 22:47:51] Using library: efficientnet-pytorch
[2025-12-02 22:47:51] Device: mps
[2025-12-02 22:47:51] PlantNet model path: /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_weights_best_acc.tar
[2025-12-02 22:47:51] Data directory: /Users/zacgarland/r_projects/agrovision/house_plant_species
[2025-12-02 22:47:51] Model save path: /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar
[2025-12-02 22:47:51] ================================================================================
[2025-12-02 22:47:51] Loading dataset...
[2025-12-02 22:47:51]    Class 'African Violet (Saintpaulia ionantha)' (idx=0): 335 images
[2025-12-02 22:47:51]    Class 'Aloe Vera' (idx=1): 247 images
[2025-12-02 22:47:51]    Class 'Anthurium (Anthurium andraeanum)' (idx=2): 451 images
[2025-12-02 22:47:51]    Class 'Areca Palm (Dypsis lutescens)' (idx=3): 189 images
[2025-12-02 22:47:51]    Class 'Asparagus Fern (Asparagus setaceus)' (idx=4): 166 images
[2025-12-02 22:47:51]    Class 'Begonia (Begonia spp.)' (idx=5): 227 images
[2025-12-02 22:47:51]    Class 'Bird of Paradise (Strelitzia reginae)' (idx=6): 175 images
[2025-12-02 22:47:51]    Class 'Birds Nest Fern (Asplenium nidus)' (idx=7): 285 images
[2025-12-02 22:47:51]    Class 'Boston Fern (Nephrolepis exaltata)' (idx=8): 297 images
[2025-12-02 22:47:51]    Class 'Calathea' (idx=9): 329 images
[2025-12-02 22:47:52]    Class 'Cast Iron Plant (Aspidistra elatior)' (idx=10): 266 images
[2025-12-02 22:47:52]    Class 'Chinese Money Plant (Pilea peperomioides)' (idx=11): 379 images
[2025-12-02 22:47:52]    Class 'Chinese evergreen (Aglaonema)' (idx=12): 510 images
[2025-12-02 22:47:52]    Class 'Christmas Cactus (Schlumbergera bridgesii)' (idx=13): 306 images
[2025-12-02 22:47:52]    Class 'Chrysanthemum' (idx=14): 208 images
[2025-12-02 22:47:52]    Class 'Ctenanthe' (idx=15): 335 images
[2025-12-02 22:47:52]    Class 'Daffodils (Narcissus spp.)' (idx=16): 415 images
[2025-12-02 22:47:52]    Class 'Dracaena' (idx=17): 261 images
[2025-12-02 22:47:52]    Class 'Dumb Cane (Dieffenbachia spp.)' (idx=18): 531 images
[2025-12-02 22:47:52]    Class 'Elephant Ear (Alocasia spp.)' (idx=19): 325 images
[2025-12-02 22:47:53]    Class 'English Ivy (Hedera helix)' (idx=20): 233 images
[2025-12-02 22:47:53]    Class 'Hyacinth (Hyacinthus orientalis)' (idx=21): 305 images
[2025-12-02 22:47:53]    Class 'Iron Cross begonia (Begonia masoniana)' (idx=22): 261 images
[2025-12-02 22:47:53]    Class 'Jade plant (Crassula ovata)' (idx=23): 347 images
[2025-12-02 22:47:53]    Class 'Kalanchoe' (idx=24): 128 images
[2025-12-02 22:47:53]    Class 'Lilium (Hemerocallis)' (idx=25): 464 images
[2025-12-02 22:47:53]    Class 'Lily of the valley (Convallaria majalis)' (idx=26): 405 images
[2025-12-02 22:47:53]    Class 'Money Tree (Pachira aquatica)' (idx=27): 359 images
[2025-12-02 22:47:53]    Class 'Monstera Deliciosa (Monstera deliciosa)' (idx=28): 539 images
[2025-12-02 22:47:53]    Class 'Orchid' (idx=29): 233 images
[2025-12-02 22:47:53]    Class 'Parlor Palm (Chamaedorea elegans)' (idx=30): 324 images
[2025-12-02 22:47:54]    Class 'Peace lily' (idx=31): 375 images
[2025-12-02 22:47:54]    Class 'Poinsettia (Euphorbia pulcherrima)' (idx=32): 305 images
[2025-12-02 22:47:54]    Class 'Polka Dot Plant (Hypoestes phyllostachya)' (idx=33): 339 images
[2025-12-02 22:47:54]    Class 'Ponytail Palm (Beaucarnea recurvata)' (idx=34): 197 images
[2025-12-02 22:47:54]    Class 'Pothos (Ivy arum)' (idx=35): 242 images
[2025-12-02 22:47:54]    Class 'Prayer Plant (Maranta leuconeura)' (idx=36): 398 images
[2025-12-02 22:47:54]    Class 'Rattlesnake Plant (Calathea lancifolia)' (idx=37): 308 images
[2025-12-02 22:47:54]    Class 'Rubber Plant (Ficus elastica)' (idx=38): 291 images
[2025-12-02 22:47:54]    Class 'Sago Palm (Cycas revoluta)' (idx=39): 202 images
[2025-12-02 22:47:54]    Class 'Schefflera' (idx=40): 322 images
[2025-12-02 22:47:54]    Class 'Snake plant (Sanseviera)' (idx=41): 390 images
[2025-12-02 22:47:54]    Class 'Tradescantia' (idx=42): 330 images
[2025-12-02 22:47:55]    Class 'Tulip' (idx=43): 338 images
[2025-12-02 22:47:55]    Class 'Venus Flytrap' (idx=44): 199 images
[2025-12-02 22:47:55]    Class 'Yucca' (idx=45): 65 images
[2025-12-02 22:47:55]    Class 'ZZ Plant (Zamioculcas zamiifolia)' (idx=46): 432 images
[2025-12-02 22:47:55] ✅ Found 14568 images in 47 classes
[2025-12-02 22:47:55] Training samples: 11654, Validation samples: 2914
[2025-12-02 22:47:55] Loading pre-trained EfficientNet B4 with PlantNet weights...
[2025-12-02 22:47:55] Number of houseplant classes: 47
[2025-12-02 22:47:55] Label range: 0 to 46 (expected: 0 to 46)
[2025-12-02 22:47:55]    Using efficientnet-pytorch library (matches PlantNet format)
[2025-12-02 22:47:55]    Step 1: Creating EfficientNet B4 with ImageNet pretrained weights...
[2025-12-02 22:47:56]    ✅ Loaded ImageNet pretrained weights
[2025-12-02 22:47:56]    Step 2: Loading PlantNet weights from: /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_weights_best_acc.tar
[2025-12-02 22:47:56]    ✅ Format verified: efficientnet-pytorch (matches!)
[2025-12-02 22:47:56]    ✅ Loaded PlantNet backbone weights
[2025-12-02 22:47:56]       Missing keys: 608 (acceptable)
[2025-12-02 22:47:56]       Unexpected keys: 706
[2025-12-02 22:47:56]    Step 3: Replacing classifier for 47 houseplant classes...
[2025-12-02 22:47:56]    ✅ Classifier replaced: 1792 -> 47
[2025-12-02 22:47:56] Setting up fine-tuning...
[2025-12-02 22:47:56]    Freezing backbone, training only classifier...
[2025-12-02 22:47:56]    Trainable parameters: 84,271 / 17,632,887 (0.5%)
[2025-12-02 22:47:56] 
================================================================================
[2025-12-02 22:47:56] Starting training...
[2025-12-02 22:47:56] ================================================================================
[2025-12-02 22:47:56] 
================================================================================
[2025-12-02 22:47:56] Epoch 1/10
[2025-12-02 22:47:56] ================================================================================
[2025-12-02 22:48:07]    Batch 10/365, Loss: 3.7224, Acc: 4.38%
[2025-12-02 22:48:18]    Batch 20/365, Loss: 3.6605, Acc: 7.03%
[2025-12-02 22:48:30]    Batch 30/365, Loss: 3.3759, Acc: 11.56%
[2025-12-02 22:48:42]    Batch 40/365, Loss: 3.2764, Acc: 14.61%
[2025-12-02 22:48:54]    Batch 50/365, Loss: 3.2621, Acc: 18.06%
[2025-12-02 22:49:05]    Batch 60/365, Loss: 3.1283, Acc: 21.77%
[2025-12-02 22:49:17]    Batch 70/365, Loss: 2.8816, Acc: 24.96%
[2025-12-02 22:49:29]    Batch 80/365, Loss: 2.9830, Acc: 27.46%
[2025-12-02 22:49:41]    Batch 90/365, Loss: 2.7588, Acc: 29.83%
[2025-12-02 22:49:54]    Batch 100/365, Loss: 2.5177, Acc: 31.56%
[2025-12-02 22:50:07]    Batch 110/365, Loss: 2.5957, Acc: 33.18%
[2025-12-02 22:50:19]    Batch 120/365, Loss: 2.7235, Acc: 34.56%
[2025-12-02 22:50:32]    Batch 130/365, Loss: 2.2817, Acc: 36.13%
[2025-12-02 22:50:43]    Batch 140/365, Loss: 2.5008, Acc: 36.79%
[2025-12-02 22:50:54]    Batch 150/365, Loss: 2.4496, Acc: 38.25%
[2025-12-02 22:51:03]    Batch 160/365, Loss: 2.1204, Acc: 39.36%
[2025-12-02 22:51:14]    Batch 170/365, Loss: 2.2483, Acc: 40.22%
[2025-12-02 22:51:24]    Batch 180/365, Loss: 2.4708, Acc: 40.87%
[2025-12-02 22:51:35]    Batch 190/365, Loss: 2.0193, Acc: 41.91%
[2025-12-02 22:51:45]    Batch 200/365, Loss: 1.5972, Acc: 42.80%
[2025-12-02 22:51:55]    Batch 210/365, Loss: 2.0112, Acc: 43.84%
[2025-12-02 22:52:06]    Batch 220/365, Loss: 1.8916, Acc: 44.64%
[2025-12-02 22:52:16]    Batch 230/365, Loss: 2.0214, Acc: 45.08%
[2025-12-02 22:52:26]    Batch 240/365, Loss: 2.2019, Acc: 45.53%
[2025-12-02 22:52:35]    Batch 250/365, Loss: 2.1237, Acc: 46.09%
[2025-12-02 22:52:46]    Batch 260/365, Loss: 1.6043, Acc: 46.69%
[2025-12-02 22:52:56]    Batch 270/365, Loss: 1.7339, Acc: 47.19%
[2025-12-02 22:53:07]    Batch 280/365, Loss: 2.0495, Acc: 47.66%
[2025-12-02 22:53:18]    Batch 290/365, Loss: 1.6707, Acc: 48.10%
[2025-12-02 22:53:28]    Batch 300/365, Loss: 1.8160, Acc: 48.33%
[2025-12-02 22:53:39]    Batch 310/365, Loss: 2.0081, Acc: 48.71%
[2025-12-02 22:53:49]    Batch 320/365, Loss: 1.8816, Acc: 49.07%
[2025-12-02 22:53:59]    Batch 330/365, Loss: 1.5036, Acc: 49.46%
[2025-12-02 22:54:08]    Batch 340/365, Loss: 1.7110, Acc: 49.81%
[2025-12-02 22:54:20]    Batch 350/365, Loss: 2.0119, Acc: 50.11%
[2025-12-02 22:54:31]    Batch 360/365, Loss: 2.0707, Acc: 50.39%
[2025-12-02 22:56:11] Train Loss: 2.3442, Train Acc: 50.53%
[2025-12-02 22:56:11] Val Loss: 1.5936, Val Acc: 67.88%
[2025-12-02 22:56:11] Learning Rate: 0.001000
[2025-12-02 22:56:11] Epoch Time: 494.9s
[2025-12-02 22:56:11] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-02 22:56:11]    ✅ Model saved! Best accuracy: 67.88%
[2025-12-02 22:56:11] 
================================================================================
[2025-12-02 22:56:11] Epoch 2/10
[2025-12-02 22:56:11] ================================================================================
[2025-12-02 22:56:24]    Batch 10/365, Loss: 1.2968, Acc: 70.31%
[2025-12-02 22:56:35]    Batch 20/365, Loss: 1.2099, Acc: 69.22%
[2025-12-02 22:56:45]    Batch 30/365, Loss: 1.2288, Acc: 68.44%
[2025-12-02 22:56:54]    Batch 40/365, Loss: 1.4271, Acc: 67.89%
[2025-12-02 22:57:05]    Batch 50/365, Loss: 1.4796, Acc: 68.44%
[2025-12-02 22:57:16]    Batch 60/365, Loss: 1.4230, Acc: 69.38%
[2025-12-02 22:57:26]    Batch 70/365, Loss: 1.3599, Acc: 69.51%
[2025-12-02 22:57:38]    Batch 80/365, Loss: 1.3119, Acc: 69.18%
[2025-12-02 22:57:49]    Batch 90/365, Loss: 1.5820, Acc: 69.13%
[2025-12-02 22:57:59]    Batch 100/365, Loss: 1.5349, Acc: 68.91%
[2025-12-02 22:58:10]    Batch 110/365, Loss: 1.3038, Acc: 68.98%
[2025-12-02 22:58:20]    Batch 120/365, Loss: 1.2826, Acc: 68.67%
[2025-12-02 22:58:30]    Batch 130/365, Loss: 1.7908, Acc: 68.46%
[2025-12-02 22:58:40]    Batch 140/365, Loss: 1.0399, Acc: 68.57%
[2025-12-02 22:58:51]    Batch 150/365, Loss: 1.1986, Acc: 68.56%
[2025-12-02 22:59:03]    Batch 160/365, Loss: 1.7489, Acc: 68.24%
[2025-12-02 22:59:14]    Batch 170/365, Loss: 1.4084, Acc: 68.27%
[2025-12-02 22:59:26]    Batch 180/365, Loss: 1.2996, Acc: 68.12%
[2025-12-02 22:59:38]    Batch 190/365, Loss: 0.9670, Acc: 68.34%
[2025-12-02 22:59:51]    Batch 200/365, Loss: 1.0973, Acc: 68.55%
[2025-12-02 23:00:03]    Batch 210/365, Loss: 1.3474, Acc: 68.42%
[2025-12-02 23:00:14]    Batch 220/365, Loss: 1.2139, Acc: 68.38%
[2025-12-02 23:00:25]    Batch 230/365, Loss: 1.2309, Acc: 68.44%
[2025-12-02 23:00:37]    Batch 240/365, Loss: 1.3200, Acc: 68.24%
[2025-12-02 23:00:47]    Batch 250/365, Loss: 1.1138, Acc: 68.22%
[2025-12-02 23:00:57]    Batch 260/365, Loss: 1.1172, Acc: 68.22%
[2025-12-02 23:01:08]    Batch 270/365, Loss: 1.4600, Acc: 68.23%
[2025-12-02 23:01:18]    Batch 280/365, Loss: 1.0623, Acc: 68.20%
[2025-12-02 23:01:28]    Batch 290/365, Loss: 1.3117, Acc: 68.12%
[2025-12-02 23:01:40]    Batch 300/365, Loss: 0.8574, Acc: 68.15%
[2025-12-02 23:01:51]    Batch 310/365, Loss: 1.4221, Acc: 68.26%
[2025-12-02 23:02:01]    Batch 320/365, Loss: 1.0904, Acc: 68.30%
[2025-12-02 23:02:11]    Batch 330/365, Loss: 1.2652, Acc: 68.35%
[2025-12-02 23:02:22]    Batch 340/365, Loss: 1.0868, Acc: 68.47%
[2025-12-02 23:02:32]    Batch 350/365, Loss: 1.4099, Acc: 68.61%
[2025-12-02 23:02:42]    Batch 360/365, Loss: 1.2267, Acc: 68.72%
[2025-12-02 23:04:20] Train Loss: 1.3523, Train Acc: 68.76%
[2025-12-02 23:04:20] Val Loss: 1.2628, Val Acc: 69.70%
[2025-12-02 23:04:20] Learning Rate: 0.001000
[2025-12-02 23:04:20] Epoch Time: 488.4s
[2025-12-02 23:04:20] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-02 23:04:20]    ✅ Model saved! Best accuracy: 69.70%
[2025-12-02 23:04:20] 
================================================================================
[2025-12-02 23:04:20] Epoch 3/10
[2025-12-02 23:04:20] ================================================================================
[2025-12-02 23:04:30]    Batch 10/365, Loss: 1.0319, Acc: 71.56%
[2025-12-02 23:04:40]    Batch 20/365, Loss: 1.4734, Acc: 71.41%
[2025-12-02 23:04:50]    Batch 30/365, Loss: 1.0670, Acc: 72.08%
[2025-12-02 23:05:00]    Batch 40/365, Loss: 1.1925, Acc: 72.19%
[2025-12-02 23:05:10]    Batch 50/365, Loss: 1.2854, Acc: 71.31%
[2025-12-02 23:05:21]    Batch 60/365, Loss: 0.8176, Acc: 71.41%
[2025-12-02 23:05:30]    Batch 70/365, Loss: 1.1787, Acc: 71.34%
[2025-12-02 23:05:40]    Batch 80/365, Loss: 1.2642, Acc: 70.82%
[2025-12-02 23:05:50]    Batch 90/365, Loss: 1.2152, Acc: 70.94%
[2025-12-02 23:06:01]    Batch 100/365, Loss: 1.4373, Acc: 70.91%
[2025-12-02 23:06:12]    Batch 110/365, Loss: 1.0321, Acc: 71.02%
[2025-12-02 23:06:22]    Batch 120/365, Loss: 1.2029, Acc: 71.12%
[2025-12-02 23:06:32]    Batch 130/365, Loss: 0.8676, Acc: 71.15%
[2025-12-02 23:06:43]    Batch 140/365, Loss: 0.9434, Acc: 71.52%
[2025-12-02 23:06:52]    Batch 150/365, Loss: 1.1008, Acc: 71.25%
[2025-12-02 23:07:02]    Batch 160/365, Loss: 0.8298, Acc: 71.46%
[2025-12-02 23:07:12]    Batch 170/365, Loss: 1.0333, Acc: 71.58%
[2025-12-02 23:07:23]    Batch 180/365, Loss: 1.0032, Acc: 71.58%
[2025-12-02 23:07:34]    Batch 190/365, Loss: 1.0690, Acc: 71.60%
[2025-12-02 23:07:45]    Batch 200/365, Loss: 1.3651, Acc: 71.78%
[2025-12-02 23:07:55]    Batch 210/365, Loss: 1.1122, Acc: 71.74%
[2025-12-02 23:08:06]    Batch 220/365, Loss: 1.3842, Acc: 71.75%
[2025-12-02 23:08:16]    Batch 230/365, Loss: 1.0238, Acc: 71.77%
[2025-12-02 23:08:27]    Batch 240/365, Loss: 1.2355, Acc: 71.80%
[2025-12-02 23:08:37]    Batch 250/365, Loss: 1.1155, Acc: 71.67%
[2025-12-02 23:08:48]    Batch 260/365, Loss: 0.8046, Acc: 71.83%
[2025-12-02 23:08:57]    Batch 270/365, Loss: 1.1602, Acc: 71.90%
[2025-12-02 23:09:07]    Batch 280/365, Loss: 1.0270, Acc: 72.15%
[2025-12-02 23:09:19]    Batch 290/365, Loss: 0.9200, Acc: 72.27%
[2025-12-02 23:09:30]    Batch 300/365, Loss: 0.5130, Acc: 72.36%
[2025-12-02 23:09:41]    Batch 310/365, Loss: 1.0755, Acc: 72.31%
[2025-12-02 23:09:51]    Batch 320/365, Loss: 1.1247, Acc: 72.21%
[2025-12-02 23:10:01]    Batch 330/365, Loss: 0.7493, Acc: 72.25%
[2025-12-02 23:10:11]    Batch 340/365, Loss: 0.8213, Acc: 72.28%
[2025-12-02 23:10:20]    Batch 350/365, Loss: 1.2341, Acc: 72.21%
[2025-12-02 23:10:31]    Batch 360/365, Loss: 0.9995, Acc: 72.25%
[2025-12-03 08:11:39] Train Loss: 1.1159, Train Acc: 72.16%
[2025-12-03 08:11:39] Val Loss: 1.1254, Val Acc: 72.13%
[2025-12-03 08:11:39] Learning Rate: 0.001000
[2025-12-03 08:11:39] Epoch Time: 32838.8s
[2025-12-03 08:11:39] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-03 08:11:39]    ✅ Model saved! Best accuracy: 72.13%
[2025-12-03 08:11:39] 
================================================================================
[2025-12-03 08:11:39] Epoch 4/10
[2025-12-03 08:11:39] ================================================================================
[2025-12-03 09:12:38]    Batch 10/365, Loss: 0.5430, Acc: 79.69%
[2025-12-03 09:28:40]    Batch 20/365, Loss: 0.7127, Acc: 78.12%
[2025-12-03 09:28:59]    Batch 30/365, Loss: 1.0632, Acc: 76.88%
[2025-12-03 09:41:22]    Batch 40/365, Loss: 0.8518, Acc: 75.55%
[2025-12-03 09:42:38]    Batch 50/365, Loss: 1.1085, Acc: 75.44%
[2025-12-03 09:48:20]    Batch 60/365, Loss: 0.7710, Acc: 75.57%
[2025-12-03 09:51:23]    Batch 70/365, Loss: 1.1514, Acc: 75.31%
[2025-12-03 09:51:48]    Batch 80/365, Loss: 1.2655, Acc: 74.65%
[2025-12-03 09:52:19]    Batch 90/365, Loss: 0.9598, Acc: 74.83%
[2025-12-03 09:52:37]    Batch 100/365, Loss: 0.8480, Acc: 74.91%
[2025-12-03 09:53:33]    Batch 110/365, Loss: 0.7632, Acc: 74.35%
[2025-12-03 09:54:33]    Batch 120/365, Loss: 1.0199, Acc: 74.64%
[2025-12-03 09:55:25]    Batch 130/365, Loss: 1.1202, Acc: 74.76%
[2025-12-03 10:01:06]    Batch 140/365, Loss: 0.6809, Acc: 74.82%
[2025-12-03 10:05:32]    Batch 150/365, Loss: 0.7687, Acc: 74.75%
[2025-12-03 10:16:05]    Batch 160/365, Loss: 1.2742, Acc: 74.86%
[2025-12-03 10:18:52]    Batch 170/365, Loss: 0.9925, Acc: 74.63%
[2025-12-03 10:19:52]    Batch 180/365, Loss: 1.1087, Acc: 74.51%
[2025-12-03 10:21:24]    Batch 190/365, Loss: 0.8390, Acc: 74.57%
[2025-12-03 10:21:42]    Batch 200/365, Loss: 1.1090, Acc: 74.42%
[2025-12-03 10:23:09]    Batch 210/365, Loss: 1.1755, Acc: 74.49%
[2025-12-03 10:29:18]    Batch 220/365, Loss: 0.8945, Acc: 74.19%
[2025-12-03 10:31:35]    Batch 230/365, Loss: 1.1008, Acc: 74.10%
[2025-12-03 10:31:51]    Batch 240/365, Loss: 1.0194, Acc: 74.19%
[2025-12-03 10:33:31]    Batch 250/365, Loss: 1.4548, Acc: 74.22%
[2025-12-03 10:36:43]    Batch 260/365, Loss: 1.4086, Acc: 74.34%
[2025-12-03 10:37:26]    Batch 270/365, Loss: 0.9673, Acc: 74.50%
[2025-12-03 10:52:14]    Batch 280/365, Loss: 1.0342, Acc: 74.49%
[2025-12-03 11:02:36]    Batch 290/365, Loss: 0.9561, Acc: 74.53%
[2025-12-03 11:09:04]    Batch 300/365, Loss: 0.7505, Acc: 74.54%
[2025-12-03 11:23:41]    Batch 310/365, Loss: 0.9505, Acc: 74.50%
[2025-12-03 11:30:35]    Batch 320/365, Loss: 1.2629, Acc: 74.52%
[2025-12-03 11:44:02]    Batch 330/365, Loss: 0.9313, Acc: 74.55%
[2025-12-03 12:14:52]    Batch 340/365, Loss: 0.9982, Acc: 74.54%
[2025-12-03 12:36:18]    Batch 350/365, Loss: 1.1946, Acc: 74.54%
[2025-12-03 12:52:24]    Batch 360/365, Loss: 1.1574, Acc: 74.51%
[2025-12-03 13:02:10] Train Loss: 0.9894, Train Acc: 74.51%
[2025-12-03 13:02:10] Val Loss: 1.0575, Val Acc: 72.41%
[2025-12-03 13:02:10] Learning Rate: 0.001000
[2025-12-03 13:02:10] Epoch Time: 17430.6s
[2025-12-03 13:02:10] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-03 13:02:10]    ✅ Model saved! Best accuracy: 72.41%
[2025-12-03 13:02:10] 
================================================================================
[2025-12-03 13:02:10] Epoch 5/10
[2025-12-03 13:02:10] ================================================================================
[2025-12-03 13:02:23]    Batch 10/365, Loss: 1.1120, Acc: 74.06%
[2025-12-03 13:02:36]    Batch 20/365, Loss: 1.1582, Acc: 74.38%
[2025-12-03 13:02:48]    Batch 30/365, Loss: 0.9913, Acc: 73.96%
[2025-12-03 13:02:59]    Batch 40/365, Loss: 1.2763, Acc: 75.55%
[2025-12-03 13:03:10]    Batch 50/365, Loss: 0.8651, Acc: 75.75%
[2025-12-03 13:03:20]    Batch 60/365, Loss: 1.0902, Acc: 75.26%
[2025-12-03 13:03:30]    Batch 70/365, Loss: 0.7002, Acc: 74.78%
[2025-12-03 13:03:40]    Batch 80/365, Loss: 0.8363, Acc: 75.66%
[2025-12-03 13:03:50]    Batch 90/365, Loss: 0.7338, Acc: 75.94%
[2025-12-03 13:04:02]    Batch 100/365, Loss: 0.9621, Acc: 76.06%
[2025-12-03 13:04:12]    Batch 110/365, Loss: 1.0741, Acc: 76.05%
[2025-12-03 13:04:23]    Batch 120/365, Loss: 0.8057, Acc: 76.30%
[2025-12-03 13:04:32]    Batch 130/365, Loss: 0.6604, Acc: 76.47%
[2025-12-03 13:04:43]    Batch 140/365, Loss: 0.7151, Acc: 76.32%
[2025-12-03 13:04:54]    Batch 150/365, Loss: 1.1756, Acc: 76.35%
[2025-12-03 13:05:04]    Batch 160/365, Loss: 0.5713, Acc: 76.48%
[2025-12-03 13:05:14]    Batch 170/365, Loss: 1.1127, Acc: 76.29%
[2025-12-03 13:05:25]    Batch 180/365, Loss: 1.1845, Acc: 76.15%
[2025-12-03 13:05:35]    Batch 190/365, Loss: 0.6287, Acc: 76.30%
[2025-12-03 13:05:46]    Batch 200/365, Loss: 0.9195, Acc: 76.41%
[2025-12-03 13:05:55]    Batch 210/365, Loss: 0.7700, Acc: 76.32%
[2025-12-03 13:06:05]    Batch 220/365, Loss: 0.9257, Acc: 76.29%
[2025-12-03 13:06:16]    Batch 230/365, Loss: 1.3879, Acc: 76.13%
[2025-12-03 13:06:28]    Batch 240/365, Loss: 0.8001, Acc: 76.08%
[2025-12-03 13:06:37]    Batch 250/365, Loss: 0.9134, Acc: 76.06%
[2025-12-03 13:06:48]    Batch 260/365, Loss: 0.8407, Acc: 76.08%
[2025-12-03 13:06:58]    Batch 270/365, Loss: 1.1714, Acc: 75.97%
[2025-12-03 13:07:09]    Batch 280/365, Loss: 1.0739, Acc: 76.02%
[2025-12-03 13:07:18]    Batch 290/365, Loss: 0.9288, Acc: 75.97%
[2025-12-03 13:07:29]    Batch 300/365, Loss: 0.7714, Acc: 75.88%
[2025-12-03 13:07:40]    Batch 310/365, Loss: 0.9667, Acc: 75.86%
[2025-12-03 13:07:51]    Batch 320/365, Loss: 0.9517, Acc: 75.75%
[2025-12-03 13:08:01]    Batch 330/365, Loss: 1.1105, Acc: 75.77%
[2025-12-03 13:08:11]    Batch 340/365, Loss: 1.1067, Acc: 75.78%
[2025-12-03 13:08:21]    Batch 350/365, Loss: 0.9682, Acc: 75.79%
[2025-12-03 13:08:31]    Batch 360/365, Loss: 1.1073, Acc: 75.71%
[2025-12-03 13:10:07] Train Loss: 0.9196, Train Acc: 75.68%
[2025-12-03 13:10:07] Val Loss: 1.0100, Val Acc: 73.23%
[2025-12-03 13:10:07] Learning Rate: 0.001000
[2025-12-03 13:10:07] Epoch Time: 477.4s
[2025-12-03 13:10:07] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-03 13:10:07]    ✅ Model saved! Best accuracy: 73.23%
[2025-12-03 13:10:07] 
================================================================================
[2025-12-03 13:10:07] Epoch 6/10
[2025-12-03 13:10:07] ================================================================================
[2025-12-03 13:10:19]    Batch 10/365, Loss: 0.8561, Acc: 74.06%
[2025-12-03 13:10:29]    Batch 20/365, Loss: 0.8940, Acc: 75.62%
[2025-12-03 13:10:39]    Batch 30/365, Loss: 1.4229, Acc: 76.04%
[2025-12-03 13:10:50]    Batch 40/365, Loss: 1.0711, Acc: 75.55%
[2025-12-03 13:10:59]    Batch 50/365, Loss: 0.8051, Acc: 76.81%
[2025-12-03 13:11:10]    Batch 60/365, Loss: 1.1885, Acc: 76.77%
[2025-12-03 13:11:20]    Batch 70/365, Loss: 0.8205, Acc: 76.47%
[2025-12-03 13:11:30]    Batch 80/365, Loss: 0.9474, Acc: 77.23%
[2025-12-03 13:11:41]    Batch 90/365, Loss: 0.9156, Acc: 77.08%
[2025-12-03 13:11:51]    Batch 100/365, Loss: 0.9144, Acc: 77.16%
[2025-12-03 13:12:01]    Batch 110/365, Loss: 0.6475, Acc: 77.10%
[2025-12-03 13:12:11]    Batch 120/365, Loss: 1.2678, Acc: 77.29%
[2025-12-03 13:12:22]    Batch 130/365, Loss: 0.8106, Acc: 77.62%
[2025-12-03 13:12:32]    Batch 140/365, Loss: 0.6431, Acc: 77.63%
[2025-12-03 13:12:42]    Batch 150/365, Loss: 1.2228, Acc: 77.38%
[2025-12-03 13:12:53]    Batch 160/365, Loss: 0.9705, Acc: 77.34%
[2025-12-03 13:13:03]    Batch 170/365, Loss: 1.1034, Acc: 77.46%
[2025-12-03 13:13:14]    Batch 180/365, Loss: 0.9078, Acc: 77.53%
[2025-12-03 13:13:24]    Batch 190/365, Loss: 0.8136, Acc: 77.57%
[2025-12-03 13:13:34]    Batch 200/365, Loss: 0.9955, Acc: 77.61%
[2025-12-03 13:13:44]    Batch 210/365, Loss: 1.0697, Acc: 77.56%
[2025-12-03 13:13:54]    Batch 220/365, Loss: 1.0619, Acc: 77.47%
[2025-12-03 13:14:07]    Batch 230/365, Loss: 0.8506, Acc: 77.28%
[2025-12-03 13:14:17]    Batch 240/365, Loss: 0.6813, Acc: 77.33%
[2025-12-03 13:14:29]    Batch 250/365, Loss: 1.0787, Acc: 77.28%
[2025-12-03 13:14:39]    Batch 260/365, Loss: 0.6021, Acc: 77.24%
[2025-12-03 13:14:51]    Batch 270/365, Loss: 1.1647, Acc: 77.14%
[2025-12-03 13:15:02]    Batch 280/365, Loss: 1.0597, Acc: 77.03%
[2025-12-03 13:15:12]    Batch 290/365, Loss: 0.7773, Acc: 76.97%
[2025-12-03 13:15:23]    Batch 300/365, Loss: 0.8557, Acc: 77.02%
[2025-12-03 13:15:34]    Batch 310/365, Loss: 0.8547, Acc: 76.94%
[2025-12-03 13:15:45]    Batch 320/365, Loss: 0.7529, Acc: 76.88%
[2025-12-03 13:15:56]    Batch 330/365, Loss: 0.7582, Acc: 76.89%
[2025-12-03 13:16:07]    Batch 340/365, Loss: 0.3590, Acc: 76.90%
[2025-12-03 13:16:20]    Batch 350/365, Loss: 0.9247, Acc: 76.81%
[2025-12-03 13:16:32]    Batch 360/365, Loss: 0.5909, Acc: 76.82%
[2025-12-03 13:18:17] Train Loss: 0.8611, Train Acc: 76.78%
[2025-12-03 13:18:17] Val Loss: 0.9799, Val Acc: 73.54%
[2025-12-03 13:18:17] Learning Rate: 0.001000
[2025-12-03 13:18:17] Epoch Time: 489.3s
[2025-12-03 13:18:17] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-03 13:18:17]    ✅ Model saved! Best accuracy: 73.54%
[2025-12-03 13:18:17] 
================================================================================
[2025-12-03 13:18:17] Epoch 7/10
[2025-12-03 13:18:17] ================================================================================
[2025-12-03 13:18:27]    Batch 10/365, Loss: 0.7819, Acc: 77.19%
[2025-12-03 13:18:38]    Batch 20/365, Loss: 0.5824, Acc: 77.66%
[2025-12-03 13:18:48]    Batch 30/365, Loss: 0.7863, Acc: 78.54%
[2025-12-03 13:18:59]    Batch 40/365, Loss: 0.7014, Acc: 78.36%
[2025-12-03 13:19:09]    Batch 50/365, Loss: 0.6669, Acc: 78.19%
[2025-12-03 13:19:20]    Batch 60/365, Loss: 0.7053, Acc: 78.59%
[2025-12-03 13:19:30]    Batch 70/365, Loss: 0.8714, Acc: 78.57%
[2025-12-03 13:19:40]    Batch 80/365, Loss: 0.7004, Acc: 78.98%
[2025-12-03 13:19:51]    Batch 90/365, Loss: 0.7136, Acc: 79.62%
[2025-12-03 13:20:02]    Batch 100/365, Loss: 1.1100, Acc: 79.28%
[2025-12-03 13:20:14]    Batch 110/365, Loss: 1.2079, Acc: 79.35%
[2025-12-03 13:20:24]    Batch 120/365, Loss: 0.6600, Acc: 79.27%
[2025-12-03 13:20:34]    Batch 130/365, Loss: 0.5948, Acc: 79.04%
[2025-12-03 13:20:44]    Batch 140/365, Loss: 0.9932, Acc: 78.93%
[2025-12-03 13:20:53]    Batch 150/365, Loss: 0.9189, Acc: 78.77%
[2025-12-03 13:21:04]    Batch 160/365, Loss: 0.8459, Acc: 78.79%
[2025-12-03 13:21:14]    Batch 170/365, Loss: 0.8973, Acc: 78.66%
[2025-12-03 13:21:24]    Batch 180/365, Loss: 0.9972, Acc: 78.52%
[2025-12-03 13:21:35]    Batch 190/365, Loss: 0.7951, Acc: 78.17%
[2025-12-03 13:21:45]    Batch 200/365, Loss: 0.8500, Acc: 78.22%
[2025-12-03 13:21:57]    Batch 210/365, Loss: 0.9513, Acc: 78.21%
[2025-12-03 13:22:08]    Batch 220/365, Loss: 0.8319, Acc: 78.28%
[2025-12-03 13:22:19]    Batch 230/365, Loss: 0.6228, Acc: 78.29%
[2025-12-03 13:22:30]    Batch 240/365, Loss: 0.7347, Acc: 78.20%
[2025-12-03 13:22:41]    Batch 250/365, Loss: 1.0517, Acc: 78.15%
[2025-12-03 13:22:54]    Batch 260/365, Loss: 0.6546, Acc: 78.28%
[2025-12-03 13:23:03]    Batch 270/365, Loss: 0.4453, Acc: 78.43%
[2025-12-03 13:23:15]    Batch 280/365, Loss: 0.6793, Acc: 78.31%
[2025-12-03 13:23:25]    Batch 290/365, Loss: 0.6801, Acc: 78.23%
[2025-12-03 13:23:35]    Batch 300/365, Loss: 0.7226, Acc: 78.22%
[2025-12-03 13:23:47]    Batch 310/365, Loss: 1.1249, Acc: 78.11%
[2025-12-03 13:23:58]    Batch 320/365, Loss: 0.5434, Acc: 78.08%
[2025-12-03 13:24:09]    Batch 330/365, Loss: 0.7569, Acc: 77.95%
[2025-12-03 13:24:20]    Batch 340/365, Loss: 0.7527, Acc: 77.98%
[2025-12-03 13:24:31]    Batch 350/365, Loss: 0.8281, Acc: 77.93%
[2025-12-03 13:24:42]    Batch 360/365, Loss: 0.6858, Acc: 77.92%
[2025-12-03 13:26:21] Train Loss: 0.8238, Train Acc: 77.84%
[2025-12-03 13:26:21] Val Loss: 0.9583, Val Acc: 73.92%
[2025-12-03 13:26:21] Learning Rate: 0.001000
[2025-12-03 13:26:21] Epoch Time: 483.7s
[2025-12-03 13:26:21] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-03 13:26:21]    ✅ Model saved! Best accuracy: 73.92%
[2025-12-03 13:26:21] 
================================================================================
[2025-12-03 13:26:21] Epoch 8/10
[2025-12-03 13:26:21] ================================================================================
[2025-12-03 13:26:32]    Batch 10/365, Loss: 0.7224, Acc: 78.75%
[2025-12-03 13:26:42]    Batch 20/365, Loss: 0.9305, Acc: 75.94%
[2025-12-03 13:26:52]    Batch 30/365, Loss: 1.0360, Acc: 76.35%
[2025-12-03 13:27:03]    Batch 40/365, Loss: 0.9286, Acc: 77.73%
[2025-12-03 13:27:13]    Batch 50/365, Loss: 0.9587, Acc: 77.44%
[2025-12-03 13:27:23]    Batch 60/365, Loss: 0.5118, Acc: 77.45%
[2025-12-03 13:27:34]    Batch 70/365, Loss: 0.7839, Acc: 77.50%
[2025-12-03 13:27:45]    Batch 80/365, Loss: 0.9677, Acc: 77.70%
[2025-12-03 13:27:55]    Batch 90/365, Loss: 0.9071, Acc: 77.60%
[2025-12-03 13:28:06]    Batch 100/365, Loss: 0.8610, Acc: 77.50%
[2025-12-03 13:28:18]    Batch 110/365, Loss: 0.6475, Acc: 77.76%
[2025-12-03 13:28:28]    Batch 120/365, Loss: 0.8888, Acc: 77.86%
[2025-12-03 13:28:39]    Batch 130/365, Loss: 0.7157, Acc: 78.05%
[2025-12-03 13:28:49]    Batch 140/365, Loss: 0.7108, Acc: 77.97%
[2025-12-03 13:28:59]    Batch 150/365, Loss: 0.8948, Acc: 77.98%
[2025-12-03 13:29:11]    Batch 160/365, Loss: 0.8607, Acc: 77.68%
[2025-12-03 13:29:22]    Batch 170/365, Loss: 0.8205, Acc: 77.61%
[2025-12-03 13:29:33]    Batch 180/365, Loss: 0.8286, Acc: 77.86%
[2025-12-03 13:29:44]    Batch 190/365, Loss: 0.9378, Acc: 77.94%
[2025-12-03 13:29:55]    Batch 200/365, Loss: 0.9217, Acc: 77.70%
[2025-12-03 13:30:05]    Batch 210/365, Loss: 0.9516, Acc: 77.56%
[2025-12-03 13:30:15]    Batch 220/365, Loss: 0.6094, Acc: 77.94%
[2025-12-03 13:30:25]    Batch 230/365, Loss: 0.9153, Acc: 77.87%
[2025-12-03 13:30:36]    Batch 240/365, Loss: 0.7227, Acc: 77.64%
[2025-12-03 13:30:46]    Batch 250/365, Loss: 0.9412, Acc: 77.67%
[2025-12-03 13:30:56]    Batch 260/365, Loss: 0.7128, Acc: 77.90%
[2025-12-03 13:31:07]    Batch 270/365, Loss: 0.5535, Acc: 77.80%
[2025-12-03 13:31:17]    Batch 280/365, Loss: 0.8307, Acc: 77.71%
[2025-12-03 13:31:28]    Batch 290/365, Loss: 1.0182, Acc: 77.72%
[2025-12-03 13:31:39]    Batch 300/365, Loss: 1.0391, Acc: 77.83%
[2025-12-03 13:31:49]    Batch 310/365, Loss: 0.8690, Acc: 77.93%
[2025-12-03 13:31:59]    Batch 320/365, Loss: 0.8056, Acc: 77.93%
[2025-12-03 13:32:10]    Batch 330/365, Loss: 0.9920, Acc: 77.95%
[2025-12-03 13:32:22]    Batch 340/365, Loss: 0.7776, Acc: 77.84%
[2025-12-03 13:32:33]    Batch 350/365, Loss: 0.6037, Acc: 77.79%
[2025-12-03 13:32:43]    Batch 360/365, Loss: 0.6514, Acc: 77.78%
[2025-12-03 13:34:22] Train Loss: 0.7898, Train Acc: 77.79%
[2025-12-03 13:34:22] Val Loss: 0.9381, Val Acc: 73.99%
[2025-12-03 13:34:22] Learning Rate: 0.001000
[2025-12-03 13:34:22] Epoch Time: 481.4s
[2025-12-03 13:34:22] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-03 13:34:23]    ✅ Model saved! Best accuracy: 73.99%
[2025-12-03 13:34:23] 
================================================================================
[2025-12-03 13:34:23] Epoch 9/10
[2025-12-03 13:34:23] ================================================================================
[2025-12-03 13:34:33]    Batch 10/365, Loss: 0.9999, Acc: 81.25%
[2025-12-03 13:34:44]    Batch 20/365, Loss: 0.4908, Acc: 79.84%
[2025-12-03 13:34:54]    Batch 30/365, Loss: 0.7359, Acc: 79.27%
[2025-12-03 13:35:06]    Batch 40/365, Loss: 0.6079, Acc: 78.91%
[2025-12-03 13:35:17]    Batch 50/365, Loss: 0.6657, Acc: 78.62%
[2025-12-03 13:35:28]    Batch 60/365, Loss: 0.7339, Acc: 78.85%
[2025-12-03 13:35:40]    Batch 70/365, Loss: 0.8578, Acc: 79.38%
[2025-12-03 13:35:52]    Batch 80/365, Loss: 0.6218, Acc: 79.06%
[2025-12-03 13:36:04]    Batch 90/365, Loss: 0.6430, Acc: 79.03%
[2025-12-03 13:36:14]    Batch 100/365, Loss: 0.8265, Acc: 78.66%
[2025-12-03 13:36:24]    Batch 110/365, Loss: 0.7532, Acc: 78.55%
[2025-12-03 13:36:35]    Batch 120/365, Loss: 0.5611, Acc: 78.46%
[2025-12-03 13:36:46]    Batch 130/365, Loss: 0.3756, Acc: 78.97%
[2025-12-03 13:36:57]    Batch 140/365, Loss: 0.3647, Acc: 79.20%
[2025-12-03 13:37:08]    Batch 150/365, Loss: 1.0709, Acc: 79.19%
[2025-12-03 13:37:19]    Batch 160/365, Loss: 0.6111, Acc: 78.93%
[2025-12-03 13:37:30]    Batch 170/365, Loss: 0.6612, Acc: 78.84%
[2025-12-03 13:37:42]    Batch 180/365, Loss: 0.5992, Acc: 78.99%
[2025-12-03 13:37:52]    Batch 190/365, Loss: 0.9112, Acc: 79.00%
[2025-12-03 13:38:02]    Batch 200/365, Loss: 0.7575, Acc: 78.84%
[2025-12-03 13:38:13]    Batch 210/365, Loss: 0.6410, Acc: 78.71%
[2025-12-03 13:38:23]    Batch 220/365, Loss: 1.0065, Acc: 78.58%
[2025-12-03 13:38:34]    Batch 230/365, Loss: 0.5008, Acc: 78.72%
[2025-12-03 13:38:46]    Batch 240/365, Loss: 0.6327, Acc: 78.70%
[2025-12-03 13:38:59]    Batch 250/365, Loss: 0.6150, Acc: 78.66%
[2025-12-03 13:39:12]    Batch 260/365, Loss: 0.7060, Acc: 78.71%
[2025-12-03 13:39:27]    Batch 270/365, Loss: 0.8919, Acc: 78.72%
[2025-12-03 13:39:41]    Batch 280/365, Loss: 0.8949, Acc: 78.43%
[2025-12-03 13:39:53]    Batch 290/365, Loss: 0.7559, Acc: 78.35%
[2025-12-03 13:40:04]    Batch 300/365, Loss: 0.5602, Acc: 78.32%
[2025-12-03 13:40:15]    Batch 310/365, Loss: 1.3273, Acc: 78.05%
[2025-12-03 13:40:27]    Batch 320/365, Loss: 1.2028, Acc: 77.99%
[2025-12-03 13:40:37]    Batch 330/365, Loss: 0.6253, Acc: 77.86%
[2025-12-03 13:40:52]    Batch 340/365, Loss: 0.4431, Acc: 77.77%
[2025-12-03 13:41:05]    Batch 350/365, Loss: 0.8255, Acc: 77.79%
[2025-12-03 13:41:16]    Batch 360/365, Loss: 0.6168, Acc: 77.87%
[2025-12-03 13:43:16] Train Loss: 0.7854, Train Acc: 77.84%
[2025-12-03 13:43:16] Val Loss: 0.9234, Val Acc: 74.33%
[2025-12-03 13:43:16] Learning Rate: 0.001000
[2025-12-03 13:43:16] Epoch Time: 533.8s
[2025-12-03 13:43:16] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-03 13:43:17]    ✅ Model saved! Best accuracy: 74.33%
[2025-12-03 13:43:17] 
================================================================================
[2025-12-03 13:43:17] Epoch 10/10
[2025-12-03 13:43:17] ================================================================================
[2025-12-03 13:43:32]    Batch 10/365, Loss: 0.7189, Acc: 81.25%
[2025-12-03 13:43:48]    Batch 20/365, Loss: 1.0859, Acc: 82.81%
[2025-12-03 13:44:04]    Batch 30/365, Loss: 0.8156, Acc: 81.77%
[2025-12-03 13:44:17]    Batch 40/365, Loss: 0.8381, Acc: 81.02%
[2025-12-03 13:44:28]    Batch 50/365, Loss: 0.7588, Acc: 80.75%
[2025-12-03 13:44:40]    Batch 60/365, Loss: 0.8384, Acc: 80.36%
[2025-12-03 13:44:51]    Batch 70/365, Loss: 0.6957, Acc: 80.31%
[2025-12-03 13:45:01]    Batch 80/365, Loss: 0.7200, Acc: 80.20%
[2025-12-03 13:45:12]    Batch 90/365, Loss: 0.7759, Acc: 79.90%
[2025-12-03 13:45:25]    Batch 100/365, Loss: 0.8588, Acc: 80.00%
[2025-12-03 13:45:39]    Batch 110/365, Loss: 0.7360, Acc: 79.86%
[2025-12-03 13:45:55]    Batch 120/365, Loss: 0.6628, Acc: 80.10%
[2025-12-03 13:46:10]    Batch 130/365, Loss: 0.7262, Acc: 80.19%
[2025-12-03 13:46:25]    Batch 140/365, Loss: 0.8977, Acc: 79.80%
[2025-12-03 13:46:35]    Batch 150/365, Loss: 0.5942, Acc: 79.81%
[2025-12-03 13:46:47]    Batch 160/365, Loss: 1.0229, Acc: 79.77%
[2025-12-03 13:47:04]    Batch 170/365, Loss: 0.5250, Acc: 79.91%
[2025-12-03 13:47:20]    Batch 180/365, Loss: 0.9322, Acc: 79.86%
[2025-12-03 13:47:36]    Batch 190/365, Loss: 0.4564, Acc: 79.54%
[2025-12-03 13:47:49]    Batch 200/365, Loss: 1.0350, Acc: 79.50%
[2025-12-03 13:53:19]    Batch 210/365, Loss: 1.0704, Acc: 79.45%
[2025-12-03 13:54:15]    Batch 220/365, Loss: 0.6619, Acc: 79.20%
[2025-12-03 13:54:43]    Batch 230/365, Loss: 0.7790, Acc: 79.01%
[2025-12-03 13:57:30]    Batch 240/365, Loss: 1.0989, Acc: 78.91%
[2025-12-03 13:59:22]    Batch 250/365, Loss: 0.6307, Acc: 78.91%
[2025-12-03 14:13:28]    Batch 260/365, Loss: 0.7566, Acc: 78.79%
[2025-12-03 15:03:57]    Batch 270/365, Loss: 0.4961, Acc: 78.82%
[2025-12-03 15:04:08]    Batch 280/365, Loss: 0.7177, Acc: 78.64%
[2025-12-03 15:04:19]    Batch 290/365, Loss: 0.6236, Acc: 78.61%
[2025-12-03 15:04:29]    Batch 300/365, Loss: 1.0805, Acc: 78.61%
[2025-12-03 15:04:38]    Batch 310/365, Loss: 0.8446, Acc: 78.70%
[2025-12-03 15:04:48]    Batch 320/365, Loss: 0.7579, Acc: 78.82%
[2025-12-03 15:04:59]    Batch 330/365, Loss: 0.6028, Acc: 78.67%
[2025-12-03 15:05:09]    Batch 340/365, Loss: 0.5249, Acc: 78.71%
[2025-12-03 15:05:20]    Batch 350/365, Loss: 0.3482, Acc: 78.71%
[2025-12-03 15:05:30]    Batch 360/365, Loss: 0.9873, Acc: 78.71%
[2025-12-03 15:07:10] Train Loss: 0.7490, Train Acc: 78.73%
[2025-12-03 15:07:10] Val Loss: 0.9083, Val Acc: 74.88%
[2025-12-03 15:07:10] Learning Rate: 0.001000
[2025-12-03 15:07:10] Epoch Time: 5032.9s
[2025-12-03 15:07:10] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar...
[2025-12-03 15:07:10]    ✅ Model saved! Best accuracy: 74.88%
[2025-12-03 15:07:10] 
================================================================================
[2025-12-03 15:07:10] Training complete!
[2025-12-03 15:07:10] Best validation accuracy: 74.88% (at epoch 10)
[2025-12-03 15:07:10] Model saved to: /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned_optimized.tar
[2025-12-03 15:07:10] ================================================================================
