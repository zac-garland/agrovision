[2025-12-02 19:17:31] ================================================================================
[2025-12-02 19:17:31] Starting fine-tuning session
[2025-12-02 19:17:31] Device: mps
[2025-12-02 19:17:31] Data directory: /Users/zacgarland/r_projects/agrovision/house_plant_species
[2025-12-02 19:17:31] Model save path: /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar
[2025-12-02 19:17:31] ================================================================================
[2025-12-02 19:17:31] Loading dataset...
[2025-12-02 19:17:31]    Class 'African Violet (Saintpaulia ionantha)' (idx=0): 335 images
[2025-12-02 19:17:31]    Class 'Aloe Vera' (idx=1): 247 images
[2025-12-02 19:17:31]    Class 'Anthurium (Anthurium andraeanum)' (idx=2): 451 images
[2025-12-02 19:17:31]    Class 'Areca Palm (Dypsis lutescens)' (idx=3): 189 images
[2025-12-02 19:17:31]    Class 'Asparagus Fern (Asparagus setaceus)' (idx=4): 166 images
[2025-12-02 19:17:31]    Class 'Begonia (Begonia spp.)' (idx=5): 227 images
[2025-12-02 19:17:31]    Class 'Bird of Paradise (Strelitzia reginae)' (idx=6): 175 images
[2025-12-02 19:17:31]    Class 'Birds Nest Fern (Asplenium nidus)' (idx=7): 285 images
[2025-12-02 19:17:31]    Class 'Boston Fern (Nephrolepis exaltata)' (idx=8): 297 images
[2025-12-02 19:17:31]    Class 'Calathea' (idx=9): 329 images
[2025-12-02 19:17:31]    Class 'Cast Iron Plant (Aspidistra elatior)' (idx=10): 266 images
[2025-12-02 19:17:31]    Class 'Chinese Money Plant (Pilea peperomioides)' (idx=11): 379 images
[2025-12-02 19:17:31]    Class 'Chinese evergreen (Aglaonema)' (idx=12): 510 images
[2025-12-02 19:17:31]    Class 'Christmas Cactus (Schlumbergera bridgesii)' (idx=13): 306 images
[2025-12-02 19:17:31]    Class 'Chrysanthemum' (idx=14): 208 images
[2025-12-02 19:17:31]    Class 'Ctenanthe' (idx=15): 335 images
[2025-12-02 19:17:31]    Class 'Daffodils (Narcissus spp.)' (idx=16): 415 images
[2025-12-02 19:17:31]    Class 'Dracaena' (idx=17): 261 images
[2025-12-02 19:17:31]    Class 'Dumb Cane (Dieffenbachia spp.)' (idx=18): 531 images
[2025-12-02 19:17:31]    Class 'Elephant Ear (Alocasia spp.)' (idx=19): 325 images
[2025-12-02 19:17:31]    Class 'English Ivy (Hedera helix)' (idx=20): 233 images
[2025-12-02 19:17:32]    Class 'Hyacinth (Hyacinthus orientalis)' (idx=21): 305 images
[2025-12-02 19:17:32]    Class 'Iron Cross begonia (Begonia masoniana)' (idx=22): 261 images
[2025-12-02 19:17:32]    Class 'Jade plant (Crassula ovata)' (idx=23): 347 images
[2025-12-02 19:17:32]    Class 'Kalanchoe' (idx=24): 128 images
[2025-12-02 19:17:32]    Class 'Lilium (Hemerocallis)' (idx=25): 464 images
[2025-12-02 19:17:32]    Class 'Lily of the valley (Convallaria majalis)' (idx=26): 405 images
[2025-12-02 19:17:32]    Class 'Money Tree (Pachira aquatica)' (idx=27): 359 images
[2025-12-02 19:17:32]    Class 'Monstera Deliciosa (Monstera deliciosa)' (idx=28): 539 images
[2025-12-02 19:17:32]    Class 'Orchid' (idx=29): 233 images
[2025-12-02 19:17:32]    Class 'Parlor Palm (Chamaedorea elegans)' (idx=30): 324 images
[2025-12-02 19:17:32]    Class 'Peace lily' (idx=31): 375 images
[2025-12-02 19:17:32]    Class 'Poinsettia (Euphorbia pulcherrima)' (idx=32): 305 images
[2025-12-02 19:17:32]    Class 'Polka Dot Plant (Hypoestes phyllostachya)' (idx=33): 339 images
[2025-12-02 19:17:32]    Class 'Ponytail Palm (Beaucarnea recurvata)' (idx=34): 197 images
[2025-12-02 19:17:32]    Class 'Pothos (Ivy arum)' (idx=35): 242 images
[2025-12-02 19:17:32]    Class 'Prayer Plant (Maranta leuconeura)' (idx=36): 398 images
[2025-12-02 19:17:32]    Class 'Rattlesnake Plant (Calathea lancifolia)' (idx=37): 308 images
[2025-12-02 19:17:32]    Class 'Rubber Plant (Ficus elastica)' (idx=38): 291 images
[2025-12-02 19:17:32]    Class 'Sago Palm (Cycas revoluta)' (idx=39): 202 images
[2025-12-02 19:17:32]    Class 'Schefflera' (idx=40): 322 images
[2025-12-02 19:17:32]    Class 'Snake plant (Sanseviera)' (idx=41): 390 images
[2025-12-02 19:17:32]    Class 'Tradescantia' (idx=42): 330 images
[2025-12-02 19:17:32]    Class 'Tulip' (idx=43): 338 images
[2025-12-02 19:17:32]    Class 'Venus Flytrap' (idx=44): 199 images
[2025-12-02 19:17:32]    Class 'Yucca' (idx=45): 65 images
[2025-12-02 19:17:32]    Class 'ZZ Plant (Zamioculcas zamiifolia)' (idx=46): 432 images
[2025-12-02 19:17:32] ✅ Found 14568 images in 47 classes
[2025-12-02 19:17:32] Training samples: 11654, Validation samples: 2914
[2025-12-02 19:17:32] Loading pre-trained EfficientNet B4...
[2025-12-02 19:17:32] Number of houseplant classes: 47
[2025-12-02 19:17:32] Label range: 0 to 46 (expected: 0 to 46)
[2025-12-02 19:17:32]    Starting with ImageNet pretrained weights...
[2025-12-02 19:17:36]    ✅ Loaded ImageNet pretrained weights
[2025-12-02 19:17:36]    Modified classifier for 47 classes
[2025-12-02 19:17:36]    Attempting to load PlantNet weights from: /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_weights_best_acc.tar
[2025-12-02 19:17:36]    ⚠️  Could not verify weights format, skipping PlantNet weights
[2025-12-02 19:17:36] Setting up fine-tuning...
[2025-12-02 19:17:36]    Freezing backbone, training only classifier...
[2025-12-02 19:17:36]    Trainable parameters: 84,271 / 17,632,887 (0.5%)
[2025-12-02 19:17:36] 
================================================================================
[2025-12-02 19:17:36] Starting training...
[2025-12-02 19:17:36] ================================================================================
[2025-12-02 19:17:36] 
================================================================================
[2025-12-02 19:17:36] Epoch 1/10
[2025-12-02 19:17:36] ================================================================================
[2025-12-02 19:17:42]    Batch 10/365, Loss: 3.7006, Acc: 6.25%
[2025-12-02 19:17:48]    Batch 20/365, Loss: 3.6827, Acc: 9.69%
[2025-12-02 19:17:55]    Batch 30/365, Loss: 3.5339, Acc: 11.25%
[2025-12-02 19:18:01]    Batch 40/365, Loss: 3.5040, Acc: 14.84%
[2025-12-02 19:18:07]    Batch 50/365, Loss: 3.4242, Acc: 17.25%
[2025-12-02 19:18:14]    Batch 60/365, Loss: 3.1897, Acc: 18.96%
[2025-12-02 19:18:20]    Batch 70/365, Loss: 3.3198, Acc: 21.16%
[2025-12-02 19:18:27]    Batch 80/365, Loss: 3.1954, Acc: 22.62%
[2025-12-02 19:18:33]    Batch 90/365, Loss: 3.0689, Acc: 24.93%
[2025-12-02 19:18:39]    Batch 100/365, Loss: 3.1215, Acc: 27.12%
[2025-12-02 19:18:47]    Batch 110/365, Loss: 2.9246, Acc: 28.92%
[2025-12-02 19:18:53]    Batch 120/365, Loss: 2.9499, Acc: 30.49%
[2025-12-02 19:18:59]    Batch 130/365, Loss: 2.9675, Acc: 31.80%
[2025-12-02 19:19:05]    Batch 140/365, Loss: 2.8177, Acc: 33.26%
[2025-12-02 19:19:12]    Batch 150/365, Loss: 2.7300, Acc: 34.69%
[2025-12-02 19:19:18]    Batch 160/365, Loss: 2.7365, Acc: 35.51%
[2025-12-02 19:19:25]    Batch 170/365, Loss: 2.6265, Acc: 36.49%
[2025-12-02 19:19:31]    Batch 180/365, Loss: 2.4876, Acc: 37.73%
[2025-12-02 19:19:37]    Batch 190/365, Loss: 2.3584, Acc: 38.72%
[2025-12-02 19:19:43]    Batch 200/365, Loss: 2.6141, Acc: 39.56%
[2025-12-02 19:19:50]    Batch 210/365, Loss: 2.3700, Acc: 40.48%
[2025-12-02 19:19:56]    Batch 220/365, Loss: 2.3338, Acc: 41.39%
[2025-12-02 19:20:02]    Batch 230/365, Loss: 2.3031, Acc: 41.86%
[2025-12-02 19:20:09]    Batch 240/365, Loss: 1.8266, Acc: 42.77%
[2025-12-02 19:20:15]    Batch 250/365, Loss: 2.1274, Acc: 43.50%
[2025-12-02 19:20:22]    Batch 260/365, Loss: 2.5005, Acc: 44.09%
[2025-12-02 19:20:28]    Batch 270/365, Loss: 2.3150, Acc: 44.53%
[2025-12-02 19:20:34]    Batch 280/365, Loss: 1.9996, Acc: 45.03%
[2025-12-02 19:20:41]    Batch 290/365, Loss: 2.2115, Acc: 45.68%
[2025-12-02 19:20:47]    Batch 300/365, Loss: 2.0558, Acc: 46.15%
[2025-12-02 19:20:53]    Batch 310/365, Loss: 1.9711, Acc: 46.65%
[2025-12-02 19:21:00]    Batch 320/365, Loss: 2.0977, Acc: 47.22%
[2025-12-02 19:21:07]    Batch 330/365, Loss: 1.8360, Acc: 47.68%
[2025-12-02 19:21:14]    Batch 340/365, Loss: 2.2843, Acc: 48.14%
[2025-12-02 19:21:21]    Batch 350/365, Loss: 2.0752, Acc: 48.58%
[2025-12-02 19:21:28]    Batch 360/365, Loss: 1.8119, Acc: 48.96%
[2025-12-02 19:22:29] Train Loss: 2.6684, Train Acc: 49.18%
[2025-12-02 19:22:29] Val Loss: 1.9339, Val Acc: 66.75%
[2025-12-02 19:22:29] Learning Rate: 0.001000
[2025-12-02 19:22:29] Epoch Time: 293.4s
[2025-12-02 19:22:29] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar...
[2025-12-02 19:22:29]    ✅ Model saved! Best accuracy: 66.75%
[2025-12-02 19:22:29] 
================================================================================
[2025-12-02 19:22:29] Epoch 2/10
[2025-12-02 19:22:29] ================================================================================
[2025-12-02 19:22:36]    Batch 10/365, Loss: 1.8695, Acc: 63.12%
[2025-12-02 19:22:43]    Batch 20/365, Loss: 1.7224, Acc: 63.91%
[2025-12-02 19:22:50]    Batch 30/365, Loss: 1.5227, Acc: 64.38%
[2025-12-02 19:22:56]    Batch 40/365, Loss: 1.7712, Acc: 64.84%
[2025-12-02 19:23:03]    Batch 50/365, Loss: 1.5990, Acc: 65.56%
[2025-12-02 19:23:09]    Batch 60/365, Loss: 1.6424, Acc: 65.47%
[2025-12-02 19:23:16]    Batch 70/365, Loss: 2.0736, Acc: 65.76%
[2025-12-02 19:23:22]    Batch 80/365, Loss: 1.9806, Acc: 65.70%
[2025-12-02 19:23:29]    Batch 90/365, Loss: 1.5718, Acc: 66.70%
[2025-12-02 19:23:35]    Batch 100/365, Loss: 1.6166, Acc: 67.00%
[2025-12-02 19:23:41]    Batch 110/365, Loss: 1.9243, Acc: 67.13%
[2025-12-02 19:23:46]    Batch 120/365, Loss: 1.3471, Acc: 67.34%
[2025-12-02 19:23:52]    Batch 130/365, Loss: 1.9092, Acc: 67.50%
[2025-12-02 19:23:58]    Batch 140/365, Loss: 1.5973, Acc: 67.03%
[2025-12-02 19:24:04]    Batch 150/365, Loss: 1.4834, Acc: 67.25%
[2025-12-02 19:24:09]    Batch 160/365, Loss: 1.7849, Acc: 67.05%
[2025-12-02 19:24:16]    Batch 170/365, Loss: 1.4684, Acc: 67.08%
[2025-12-02 19:24:21]    Batch 180/365, Loss: 1.7607, Acc: 66.96%
[2025-12-02 19:24:27]    Batch 190/365, Loss: 1.4155, Acc: 67.09%
[2025-12-02 19:24:34]    Batch 200/365, Loss: 1.6985, Acc: 67.19%
[2025-12-02 19:24:39]    Batch 210/365, Loss: 1.5003, Acc: 67.32%
[2025-12-02 19:24:46]    Batch 220/365, Loss: 1.3645, Acc: 67.26%
[2025-12-02 19:24:52]    Batch 230/365, Loss: 1.2898, Acc: 67.47%
[2025-12-02 19:24:59]    Batch 240/365, Loss: 1.6779, Acc: 67.62%
[2025-12-02 19:25:05]    Batch 250/365, Loss: 1.5100, Acc: 67.59%
[2025-12-02 19:25:10]    Batch 260/365, Loss: 1.4691, Acc: 67.73%
[2025-12-02 19:25:16]    Batch 270/365, Loss: 1.6938, Acc: 67.86%
[2025-12-02 19:25:23]    Batch 280/365, Loss: 1.5028, Acc: 68.01%
[2025-12-02 19:25:29]    Batch 290/365, Loss: 1.4475, Acc: 67.93%
[2025-12-02 19:25:35]    Batch 300/365, Loss: 1.1335, Acc: 68.10%
[2025-12-02 19:25:41]    Batch 310/365, Loss: 1.5513, Acc: 68.02%
[2025-12-02 19:25:47]    Batch 320/365, Loss: 1.5300, Acc: 68.15%
[2025-12-02 19:25:54]    Batch 330/365, Loss: 1.4585, Acc: 68.16%
[2025-12-02 19:26:00]    Batch 340/365, Loss: 1.2274, Acc: 68.16%
[2025-12-02 19:26:06]    Batch 350/365, Loss: 1.4985, Acc: 68.29%
[2025-12-02 19:26:13]    Batch 360/365, Loss: 1.4016, Acc: 68.31%
[2025-12-02 19:27:09] Train Loss: 1.5750, Train Acc: 68.29%
[2025-12-02 19:27:09] Val Loss: 1.4071, Val Acc: 73.34%
[2025-12-02 19:27:09] Learning Rate: 0.001000
[2025-12-02 19:27:09] Epoch Time: 279.8s
[2025-12-02 19:27:09] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar...
[2025-12-02 19:27:09]    ✅ Model saved! Best accuracy: 73.34%
[2025-12-02 19:27:09] 
================================================================================
[2025-12-02 19:27:09] Epoch 3/10
[2025-12-02 19:27:09] ================================================================================
[2025-12-02 19:27:15]    Batch 10/365, Loss: 1.2091, Acc: 75.00%
[2025-12-02 19:27:22]    Batch 20/365, Loss: 1.0043, Acc: 75.31%
[2025-12-02 19:27:28]    Batch 30/365, Loss: 1.1531, Acc: 74.79%
[2025-12-02 19:27:34]    Batch 40/365, Loss: 1.2515, Acc: 74.06%
[2025-12-02 19:27:40]    Batch 50/365, Loss: 1.3017, Acc: 74.19%
[2025-12-02 19:27:47]    Batch 60/365, Loss: 1.2871, Acc: 74.06%
[2025-12-02 19:27:54]    Batch 70/365, Loss: 1.2668, Acc: 73.53%
[2025-12-02 19:28:00]    Batch 80/365, Loss: 1.1727, Acc: 73.55%
[2025-12-02 19:28:06]    Batch 90/365, Loss: 1.1039, Acc: 73.92%
[2025-12-02 19:28:12]    Batch 100/365, Loss: 1.1232, Acc: 73.94%
[2025-12-02 19:28:18]    Batch 110/365, Loss: 1.5464, Acc: 73.66%
[2025-12-02 19:28:24]    Batch 120/365, Loss: 1.4481, Acc: 73.75%
[2025-12-02 19:28:30]    Batch 130/365, Loss: 1.3494, Acc: 73.68%
[2025-12-02 19:28:36]    Batch 140/365, Loss: 1.1794, Acc: 73.50%
[2025-12-02 19:28:42]    Batch 150/365, Loss: 1.5683, Acc: 73.65%
[2025-12-02 19:28:48]    Batch 160/365, Loss: 1.3602, Acc: 73.54%
[2025-12-02 19:28:54]    Batch 170/365, Loss: 1.3945, Acc: 73.51%
[2025-12-02 19:29:00]    Batch 180/365, Loss: 1.0639, Acc: 73.56%
[2025-12-02 19:29:07]    Batch 190/365, Loss: 1.0169, Acc: 73.50%
[2025-12-02 19:29:12]    Batch 200/365, Loss: 0.9174, Acc: 73.72%
[2025-12-02 19:29:18]    Batch 210/365, Loss: 1.2988, Acc: 73.78%
[2025-12-02 19:29:24]    Batch 220/365, Loss: 1.2659, Acc: 73.86%
[2025-12-02 19:29:30]    Batch 230/365, Loss: 1.0150, Acc: 73.75%
[2025-12-02 19:29:36]    Batch 240/365, Loss: 0.8962, Acc: 73.89%
[2025-12-02 19:29:43]    Batch 250/365, Loss: 1.1554, Acc: 73.86%
[2025-12-02 19:29:48]    Batch 260/365, Loss: 1.2229, Acc: 73.69%
[2025-12-02 19:29:54]    Batch 270/365, Loss: 1.0386, Acc: 73.53%
[2025-12-02 19:30:00]    Batch 280/365, Loss: 1.1046, Acc: 73.63%
[2025-12-02 19:30:07]    Batch 290/365, Loss: 1.2137, Acc: 73.47%
[2025-12-02 19:30:14]    Batch 300/365, Loss: 1.6386, Acc: 73.46%
[2025-12-02 19:30:20]    Batch 310/365, Loss: 1.1510, Acc: 73.39%
[2025-12-02 19:30:26]    Batch 320/365, Loss: 1.1540, Acc: 73.34%
[2025-12-02 19:30:33]    Batch 330/365, Loss: 0.9999, Acc: 73.29%
[2025-12-02 19:30:39]    Batch 340/365, Loss: 1.5011, Acc: 73.30%
[2025-12-02 19:30:45]    Batch 350/365, Loss: 1.1987, Acc: 73.36%
[2025-12-02 19:30:51]    Batch 360/365, Loss: 1.2491, Acc: 73.32%
[2025-12-02 19:31:48] Train Loss: 1.2282, Train Acc: 73.33%
[2025-12-02 19:31:48] Val Loss: 1.1609, Val Acc: 75.57%
[2025-12-02 19:31:48] Learning Rate: 0.001000
[2025-12-02 19:31:48] Epoch Time: 278.8s
[2025-12-02 19:31:48] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar...
[2025-12-02 19:31:48]    ✅ Model saved! Best accuracy: 75.57%
[2025-12-02 19:31:48] 
================================================================================
[2025-12-02 19:31:48] Epoch 4/10
[2025-12-02 19:31:48] ================================================================================
[2025-12-02 19:31:54]    Batch 10/365, Loss: 1.5745, Acc: 72.50%
[2025-12-02 19:32:01]    Batch 20/365, Loss: 0.9861, Acc: 74.53%
[2025-12-02 19:32:07]    Batch 30/365, Loss: 1.1198, Acc: 75.73%
[2025-12-02 19:32:13]    Batch 40/365, Loss: 1.1597, Acc: 75.78%
[2025-12-02 19:32:18]    Batch 50/365, Loss: 0.8856, Acc: 75.06%
[2025-12-02 19:32:24]    Batch 60/365, Loss: 0.8026, Acc: 74.69%
[2025-12-02 19:32:29]    Batch 70/365, Loss: 1.4154, Acc: 74.64%
[2025-12-02 19:32:36]    Batch 80/365, Loss: 1.1312, Acc: 74.96%
[2025-12-02 19:32:42]    Batch 90/365, Loss: 0.9827, Acc: 74.76%
[2025-12-02 19:32:48]    Batch 100/365, Loss: 1.1361, Acc: 74.91%
[2025-12-02 19:32:55]    Batch 110/365, Loss: 1.1400, Acc: 74.91%
[2025-12-02 19:33:01]    Batch 120/365, Loss: 0.8845, Acc: 75.10%
[2025-12-02 19:33:07]    Batch 130/365, Loss: 1.3041, Acc: 75.22%
[2025-12-02 19:33:13]    Batch 140/365, Loss: 0.8810, Acc: 75.07%
[2025-12-02 19:33:20]    Batch 150/365, Loss: 1.1751, Acc: 75.19%
[2025-12-02 19:33:27]    Batch 160/365, Loss: 1.0487, Acc: 75.16%
[2025-12-02 19:33:32]    Batch 170/365, Loss: 1.0281, Acc: 75.26%
[2025-12-02 19:33:39]    Batch 180/365, Loss: 0.9205, Acc: 75.54%
[2025-12-02 19:33:44]    Batch 190/365, Loss: 1.0271, Acc: 75.58%
[2025-12-02 19:33:51]    Batch 200/365, Loss: 1.1170, Acc: 75.39%
[2025-12-02 19:33:57]    Batch 210/365, Loss: 1.0907, Acc: 75.33%
[2025-12-02 19:34:03]    Batch 220/365, Loss: 1.0344, Acc: 75.37%
[2025-12-02 19:34:09]    Batch 230/365, Loss: 1.3327, Acc: 75.35%
[2025-12-02 19:34:15]    Batch 240/365, Loss: 0.9041, Acc: 75.33%
[2025-12-02 19:34:22]    Batch 250/365, Loss: 1.0525, Acc: 75.29%
[2025-12-02 19:34:28]    Batch 260/365, Loss: 0.8848, Acc: 75.26%
[2025-12-02 19:34:34]    Batch 270/365, Loss: 1.1608, Acc: 75.41%
[2025-12-02 19:34:40]    Batch 280/365, Loss: 0.9189, Acc: 75.59%
[2025-12-02 19:34:46]    Batch 290/365, Loss: 0.8553, Acc: 75.61%
[2025-12-02 19:34:52]    Batch 300/365, Loss: 0.8694, Acc: 75.50%
[2025-12-02 19:34:58]    Batch 310/365, Loss: 0.8451, Acc: 75.55%
[2025-12-02 19:35:05]    Batch 320/365, Loss: 0.9473, Acc: 75.66%
[2025-12-02 19:35:10]    Batch 330/365, Loss: 1.2072, Acc: 75.65%
[2025-12-02 19:35:17]    Batch 340/365, Loss: 1.1437, Acc: 75.73%
[2025-12-02 19:35:24]    Batch 350/365, Loss: 1.1432, Acc: 75.71%
[2025-12-02 19:35:30]    Batch 360/365, Loss: 1.3092, Acc: 75.68%
[2025-12-02 19:36:27] Train Loss: 1.0562, Train Acc: 75.65%
[2025-12-02 19:36:27] Val Loss: 1.0263, Val Acc: 77.56%
[2025-12-02 19:36:27] Learning Rate: 0.001000
[2025-12-02 19:36:27] Epoch Time: 278.9s
[2025-12-02 19:36:27] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar...
[2025-12-02 19:36:27]    ✅ Model saved! Best accuracy: 77.56%
[2025-12-02 19:36:27] 
================================================================================
[2025-12-02 19:36:27] Epoch 5/10
[2025-12-02 19:36:27] ================================================================================
[2025-12-02 19:36:33]    Batch 10/365, Loss: 1.0858, Acc: 78.75%
[2025-12-02 19:36:39]    Batch 20/365, Loss: 1.2291, Acc: 77.03%
[2025-12-02 19:36:46]    Batch 30/365, Loss: 0.6964, Acc: 78.85%
[2025-12-02 19:36:52]    Batch 40/365, Loss: 0.9638, Acc: 78.05%
[2025-12-02 19:36:58]    Batch 50/365, Loss: 1.0390, Acc: 77.62%
[2025-12-02 19:37:04]    Batch 60/365, Loss: 0.8282, Acc: 77.66%
[2025-12-02 19:37:11]    Batch 70/365, Loss: 0.9222, Acc: 77.23%
[2025-12-02 19:37:16]    Batch 80/365, Loss: 0.8747, Acc: 77.30%
[2025-12-02 19:37:22]    Batch 90/365, Loss: 1.2134, Acc: 76.81%
[2025-12-02 19:37:29]    Batch 100/365, Loss: 0.9719, Acc: 76.31%
[2025-12-02 19:37:35]    Batch 110/365, Loss: 0.9020, Acc: 76.25%
[2025-12-02 19:37:41]    Batch 120/365, Loss: 0.9893, Acc: 76.22%
[2025-12-02 19:37:46]    Batch 130/365, Loss: 1.2320, Acc: 76.42%
[2025-12-02 19:37:52]    Batch 140/365, Loss: 1.2066, Acc: 76.41%
[2025-12-02 19:37:59]    Batch 150/365, Loss: 0.9035, Acc: 76.69%
[2025-12-02 19:38:04]    Batch 160/365, Loss: 0.8608, Acc: 76.84%
[2025-12-02 19:38:11]    Batch 170/365, Loss: 0.9399, Acc: 76.88%
[2025-12-02 19:38:18]    Batch 180/365, Loss: 0.8677, Acc: 76.75%
[2025-12-02 19:38:24]    Batch 190/365, Loss: 0.9581, Acc: 76.73%
[2025-12-02 19:38:30]    Batch 200/365, Loss: 1.1421, Acc: 76.77%
[2025-12-02 19:38:37]    Batch 210/365, Loss: 0.9138, Acc: 76.93%
[2025-12-02 19:38:42]    Batch 220/365, Loss: 0.9198, Acc: 76.88%
[2025-12-02 19:38:48]    Batch 230/365, Loss: 1.2793, Acc: 77.04%
[2025-12-02 19:38:54]    Batch 240/365, Loss: 1.0017, Acc: 77.01%
[2025-12-02 19:39:00]    Batch 250/365, Loss: 0.9181, Acc: 77.04%
[2025-12-02 19:39:06]    Batch 260/365, Loss: 1.0174, Acc: 77.12%
[2025-12-02 19:39:13]    Batch 270/365, Loss: 0.7138, Acc: 77.00%
[2025-12-02 19:39:18]    Batch 280/365, Loss: 1.0587, Acc: 77.04%
[2025-12-02 19:39:25]    Batch 290/365, Loss: 0.8392, Acc: 77.06%
[2025-12-02 19:39:31]    Batch 300/365, Loss: 0.9555, Acc: 77.17%
[2025-12-02 19:39:37]    Batch 310/365, Loss: 0.6591, Acc: 77.26%
[2025-12-02 19:39:43]    Batch 320/365, Loss: 0.9777, Acc: 77.17%
[2025-12-02 19:39:49]    Batch 330/365, Loss: 0.9796, Acc: 77.09%
[2025-12-02 19:39:56]    Batch 340/365, Loss: 0.8429, Acc: 76.99%
[2025-12-02 19:40:02]    Batch 350/365, Loss: 0.7973, Acc: 76.99%
[2025-12-02 19:40:09]    Batch 360/365, Loss: 0.6537, Acc: 77.09%
[2025-12-02 19:41:06] Train Loss: 0.9525, Train Acc: 77.09%
[2025-12-02 19:41:06] Val Loss: 0.9918, Val Acc: 77.14%
[2025-12-02 19:41:06] Learning Rate: 0.001000
[2025-12-02 19:41:06] Epoch Time: 278.8s
[2025-12-02 19:41:06] 
================================================================================
[2025-12-02 19:41:06] Epoch 6/10
[2025-12-02 19:41:06] ================================================================================
[2025-12-02 19:41:12]    Batch 10/365, Loss: 0.6466, Acc: 74.69%
[2025-12-02 19:41:19]    Batch 20/365, Loss: 0.8676, Acc: 78.12%
[2025-12-02 19:41:25]    Batch 30/365, Loss: 1.0644, Acc: 78.96%
[2025-12-02 19:41:31]    Batch 40/365, Loss: 1.0050, Acc: 79.06%
[2025-12-02 19:41:37]    Batch 50/365, Loss: 1.0070, Acc: 78.88%
[2025-12-02 19:41:42]    Batch 60/365, Loss: 0.7644, Acc: 78.49%
[2025-12-02 19:41:48]    Batch 70/365, Loss: 0.7293, Acc: 79.11%
[2025-12-02 19:41:54]    Batch 80/365, Loss: 0.7519, Acc: 78.63%
[2025-12-02 19:42:01]    Batch 90/365, Loss: 0.6087, Acc: 78.68%
[2025-12-02 19:42:07]    Batch 100/365, Loss: 0.8104, Acc: 78.84%
[2025-12-02 19:42:13]    Batch 110/365, Loss: 1.2140, Acc: 78.69%
[2025-12-02 19:42:19]    Batch 120/365, Loss: 0.8077, Acc: 78.75%
[2025-12-02 19:42:26]    Batch 130/365, Loss: 1.1169, Acc: 78.53%
[2025-12-02 19:42:33]    Batch 140/365, Loss: 0.7885, Acc: 78.48%
[2025-12-02 19:42:39]    Batch 150/365, Loss: 0.5999, Acc: 78.67%
[2025-12-02 19:42:45]    Batch 160/365, Loss: 0.9760, Acc: 78.55%
[2025-12-02 19:42:51]    Batch 170/365, Loss: 1.0791, Acc: 78.49%
[2025-12-02 19:42:58]    Batch 180/365, Loss: 0.9389, Acc: 78.49%
[2025-12-02 19:43:04]    Batch 190/365, Loss: 0.8812, Acc: 78.54%
[2025-12-02 19:43:10]    Batch 200/365, Loss: 0.8285, Acc: 78.47%
[2025-12-02 19:43:16]    Batch 210/365, Loss: 0.6796, Acc: 78.60%
[2025-12-02 19:43:22]    Batch 220/365, Loss: 1.1566, Acc: 78.44%
[2025-12-02 19:43:28]    Batch 230/365, Loss: 0.7310, Acc: 78.52%
[2025-12-02 19:43:35]    Batch 240/365, Loss: 0.8976, Acc: 78.52%
[2025-12-02 19:43:41]    Batch 250/365, Loss: 0.8352, Acc: 78.36%
[2025-12-02 19:43:47]    Batch 260/365, Loss: 0.6442, Acc: 78.39%
[2025-12-02 19:43:53]    Batch 270/365, Loss: 0.9347, Acc: 78.29%
[2025-12-02 19:43:59]    Batch 280/365, Loss: 0.7150, Acc: 78.31%
[2025-12-02 19:44:05]    Batch 290/365, Loss: 0.7760, Acc: 78.42%
[2025-12-02 19:44:10]    Batch 300/365, Loss: 0.6941, Acc: 78.46%
[2025-12-02 19:44:17]    Batch 310/365, Loss: 0.7732, Acc: 78.33%
[2025-12-02 19:44:23]    Batch 320/365, Loss: 0.7480, Acc: 78.40%
[2025-12-02 19:44:30]    Batch 330/365, Loss: 0.8049, Acc: 78.31%
[2025-12-02 19:44:35]    Batch 340/365, Loss: 0.5352, Acc: 78.41%
[2025-12-02 19:44:42]    Batch 350/365, Loss: 0.8547, Acc: 78.38%
[2025-12-02 19:44:48]    Batch 360/365, Loss: 0.6758, Acc: 78.45%
[2025-12-02 19:45:45] Train Loss: 0.8846, Train Acc: 78.39%
[2025-12-02 19:45:45] Val Loss: 0.9341, Val Acc: 78.48%
[2025-12-02 19:45:45] Learning Rate: 0.001000
[2025-12-02 19:45:45] Epoch Time: 279.0s
[2025-12-02 19:45:45] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar...
[2025-12-02 19:45:45]    ✅ Model saved! Best accuracy: 78.48%
[2025-12-02 19:45:45] 
================================================================================
[2025-12-02 19:45:45] Epoch 7/10
[2025-12-02 19:45:45] ================================================================================
[2025-12-02 19:45:51]    Batch 10/365, Loss: 0.7502, Acc: 80.31%
[2025-12-02 19:45:57]    Batch 20/365, Loss: 0.9965, Acc: 81.25%
[2025-12-02 19:46:03]    Batch 30/365, Loss: 0.5337, Acc: 81.98%
[2025-12-02 19:46:09]    Batch 40/365, Loss: 0.6672, Acc: 81.48%
[2025-12-02 19:46:16]    Batch 50/365, Loss: 0.7937, Acc: 80.06%
[2025-12-02 19:46:22]    Batch 60/365, Loss: 0.7345, Acc: 79.69%
[2025-12-02 19:46:28]    Batch 70/365, Loss: 0.9722, Acc: 79.38%
[2025-12-02 19:46:34]    Batch 80/365, Loss: 0.5403, Acc: 79.53%
[2025-12-02 19:46:40]    Batch 90/365, Loss: 0.9281, Acc: 79.62%
[2025-12-02 19:46:46]    Batch 100/365, Loss: 0.7439, Acc: 79.28%
[2025-12-02 19:46:53]    Batch 110/365, Loss: 0.9295, Acc: 79.38%
[2025-12-02 19:46:59]    Batch 120/365, Loss: 0.8117, Acc: 79.35%
[2025-12-02 19:47:05]    Batch 130/365, Loss: 0.6920, Acc: 79.30%
[2025-12-02 19:47:11]    Batch 140/365, Loss: 0.9010, Acc: 79.29%
[2025-12-02 19:47:18]    Batch 150/365, Loss: 1.1925, Acc: 79.38%
[2025-12-02 19:47:24]    Batch 160/365, Loss: 0.7928, Acc: 79.47%
[2025-12-02 19:47:29]    Batch 170/365, Loss: 0.8287, Acc: 79.80%
[2025-12-02 19:47:35]    Batch 180/365, Loss: 0.8476, Acc: 80.05%
[2025-12-02 19:47:41]    Batch 190/365, Loss: 0.8993, Acc: 80.10%
[2025-12-02 19:47:48]    Batch 200/365, Loss: 1.2075, Acc: 80.02%
[2025-12-02 19:47:54]    Batch 210/365, Loss: 0.8819, Acc: 79.97%
[2025-12-02 19:48:00]    Batch 220/365, Loss: 0.9020, Acc: 79.72%
[2025-12-02 19:48:07]    Batch 230/365, Loss: 1.0360, Acc: 79.62%
[2025-12-02 19:48:13]    Batch 240/365, Loss: 0.8148, Acc: 79.52%
[2025-12-02 19:48:20]    Batch 250/365, Loss: 0.9902, Acc: 79.46%
[2025-12-02 19:48:26]    Batch 260/365, Loss: 1.1998, Acc: 79.52%
[2025-12-02 19:48:32]    Batch 270/365, Loss: 0.6327, Acc: 79.57%
[2025-12-02 19:48:38]    Batch 280/365, Loss: 1.1112, Acc: 79.53%
[2025-12-02 19:48:44]    Batch 290/365, Loss: 0.9373, Acc: 79.44%
[2025-12-02 19:48:50]    Batch 300/365, Loss: 0.9979, Acc: 79.45%
[2025-12-02 19:48:56]    Batch 310/365, Loss: 0.9626, Acc: 79.35%
[2025-12-02 19:49:02]    Batch 320/365, Loss: 0.5364, Acc: 79.38%
[2025-12-02 19:49:08]    Batch 330/365, Loss: 0.5894, Acc: 79.33%
[2025-12-02 19:49:14]    Batch 340/365, Loss: 0.6814, Acc: 79.29%
[2025-12-02 19:49:20]    Batch 350/365, Loss: 0.9466, Acc: 79.28%
[2025-12-02 19:49:26]    Batch 360/365, Loss: 0.8760, Acc: 79.23%
[2025-12-02 19:50:24] Train Loss: 0.8348, Train Acc: 79.10%
[2025-12-02 19:50:24] Val Loss: 0.8685, Val Acc: 79.51%
[2025-12-02 19:50:24] Learning Rate: 0.001000
[2025-12-02 19:50:24] Epoch Time: 278.6s
[2025-12-02 19:50:24] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar...
[2025-12-02 19:50:24]    ✅ Model saved! Best accuracy: 79.51%
[2025-12-02 19:50:24] 
================================================================================
[2025-12-02 19:50:24] Epoch 8/10
[2025-12-02 19:50:24] ================================================================================
[2025-12-02 19:50:29]    Batch 10/365, Loss: 0.4350, Acc: 80.94%
[2025-12-02 19:50:35]    Batch 20/365, Loss: 0.7637, Acc: 81.09%
[2025-12-02 19:50:42]    Batch 30/365, Loss: 0.8373, Acc: 80.10%
[2025-12-02 19:50:48]    Batch 40/365, Loss: 0.8574, Acc: 80.86%
[2025-12-02 19:50:54]    Batch 50/365, Loss: 0.5208, Acc: 80.75%
[2025-12-02 19:51:00]    Batch 60/365, Loss: 0.6340, Acc: 81.04%
[2025-12-02 19:51:06]    Batch 70/365, Loss: 0.9377, Acc: 80.85%
[2025-12-02 19:51:12]    Batch 80/365, Loss: 1.1827, Acc: 80.86%
[2025-12-02 19:51:18]    Batch 90/365, Loss: 0.7219, Acc: 80.90%
[2025-12-02 19:51:25]    Batch 100/365, Loss: 0.6295, Acc: 81.03%
[2025-12-02 19:51:31]    Batch 110/365, Loss: 1.0044, Acc: 80.68%
[2025-12-02 19:51:38]    Batch 120/365, Loss: 0.9302, Acc: 80.39%
[2025-12-02 19:51:43]    Batch 130/365, Loss: 0.8620, Acc: 80.65%
[2025-12-02 19:51:49]    Batch 140/365, Loss: 0.8120, Acc: 80.67%
[2025-12-02 19:51:55]    Batch 150/365, Loss: 0.8003, Acc: 80.65%
[2025-12-02 19:52:02]    Batch 160/365, Loss: 0.6870, Acc: 80.51%
[2025-12-02 19:52:07]    Batch 170/365, Loss: 0.6605, Acc: 80.59%
[2025-12-02 19:52:14]    Batch 180/365, Loss: 0.4836, Acc: 80.66%
[2025-12-02 19:52:20]    Batch 190/365, Loss: 0.6051, Acc: 80.61%
[2025-12-02 19:52:26]    Batch 200/365, Loss: 0.8813, Acc: 80.45%
[2025-12-02 19:52:33]    Batch 210/365, Loss: 0.7816, Acc: 80.31%
[2025-12-02 19:52:39]    Batch 220/365, Loss: 0.5497, Acc: 80.41%
[2025-12-02 19:52:46]    Batch 230/365, Loss: 0.4545, Acc: 80.45%
[2025-12-02 19:52:52]    Batch 240/365, Loss: 0.7318, Acc: 80.39%
[2025-12-02 19:52:58]    Batch 250/365, Loss: 0.5750, Acc: 80.49%
[2025-12-02 19:53:04]    Batch 260/365, Loss: 0.6533, Acc: 80.41%
[2025-12-02 19:53:11]    Batch 270/365, Loss: 0.6739, Acc: 80.37%
[2025-12-02 19:53:17]    Batch 280/365, Loss: 1.0743, Acc: 80.33%
[2025-12-02 19:53:23]    Batch 290/365, Loss: 0.5621, Acc: 80.32%
[2025-12-02 19:53:29]    Batch 300/365, Loss: 1.0410, Acc: 80.36%
[2025-12-02 19:53:35]    Batch 310/365, Loss: 0.6484, Acc: 80.39%
[2025-12-02 19:53:41]    Batch 320/365, Loss: 0.7226, Acc: 80.49%
[2025-12-02 19:53:47]    Batch 330/365, Loss: 0.6238, Acc: 80.45%
[2025-12-02 19:53:54]    Batch 340/365, Loss: 0.6013, Acc: 80.48%
[2025-12-02 19:54:00]    Batch 350/365, Loss: 0.8616, Acc: 80.43%
[2025-12-02 19:54:06]    Batch 360/365, Loss: 0.7370, Acc: 80.38%
[2025-12-02 19:55:03] Train Loss: 0.7867, Train Acc: 80.34%
[2025-12-02 19:55:03] Val Loss: 0.8353, Val Acc: 80.03%
[2025-12-02 19:55:03] Learning Rate: 0.001000
[2025-12-02 19:55:03] Epoch Time: 279.1s
[2025-12-02 19:55:03] ✅ New best model! Saving to /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar...
[2025-12-02 19:55:03]    ✅ Model saved! Best accuracy: 80.03%
[2025-12-02 19:55:03] 
================================================================================
[2025-12-02 19:55:03] Epoch 9/10
[2025-12-02 19:55:03] ================================================================================
[2025-12-02 19:55:09]    Batch 10/365, Loss: 0.6948, Acc: 83.12%
[2025-12-02 19:55:15]    Batch 20/365, Loss: 0.6075, Acc: 82.34%
[2025-12-02 19:55:22]    Batch 30/365, Loss: 0.9413, Acc: 82.40%
[2025-12-02 19:55:28]    Batch 40/365, Loss: 0.8601, Acc: 81.64%
[2025-12-02 19:55:34]    Batch 50/365, Loss: 0.6264, Acc: 81.88%
[2025-12-02 19:55:40]    Batch 60/365, Loss: 0.7555, Acc: 81.67%
[2025-12-02 19:55:46]    Batch 70/365, Loss: 0.5807, Acc: 81.56%
[2025-12-02 19:55:53]    Batch 80/365, Loss: 0.8057, Acc: 81.48%
[2025-12-02 19:55:59]    Batch 90/365, Loss: 1.2288, Acc: 81.42%
[2025-12-02 19:56:06]    Batch 100/365, Loss: 0.8995, Acc: 81.41%
[2025-12-02 19:56:12]    Batch 110/365, Loss: 0.6905, Acc: 81.48%
[2025-12-02 19:56:18]    Batch 120/365, Loss: 1.0205, Acc: 81.56%
[2025-12-02 19:56:23]    Batch 130/365, Loss: 0.9587, Acc: 81.25%
[2025-12-02 19:56:29]    Batch 140/365, Loss: 0.9431, Acc: 81.29%
[2025-12-02 19:56:36]    Batch 150/365, Loss: 0.8862, Acc: 81.25%
[2025-12-02 19:56:43]    Batch 160/365, Loss: 0.8908, Acc: 81.31%
[2025-12-02 19:56:48]    Batch 170/365, Loss: 0.5340, Acc: 81.51%
[2025-12-02 19:56:54]    Batch 180/365, Loss: 0.7513, Acc: 81.46%
[2025-12-02 19:57:01]    Batch 190/365, Loss: 0.7732, Acc: 81.27%
[2025-12-02 19:57:07]    Batch 200/365, Loss: 0.7296, Acc: 81.25%
[2025-12-02 19:57:12]    Batch 210/365, Loss: 0.8725, Acc: 81.18%
[2025-12-02 19:57:18]    Batch 220/365, Loss: 1.0357, Acc: 81.04%
[2025-12-02 19:57:24]    Batch 230/365, Loss: 0.8790, Acc: 81.01%
[2025-12-02 19:57:31]    Batch 240/365, Loss: 0.8735, Acc: 80.79%
[2025-12-02 19:57:36]    Batch 250/365, Loss: 0.6994, Acc: 80.85%
[2025-12-02 19:57:43]    Batch 260/365, Loss: 0.6227, Acc: 80.81%
[2025-12-02 19:57:49]    Batch 270/365, Loss: 0.6899, Acc: 80.83%
[2025-12-02 19:57:55]    Batch 280/365, Loss: 0.6870, Acc: 80.83%
[2025-12-02 19:58:01]    Batch 290/365, Loss: 1.1532, Acc: 80.83%
[2025-12-02 19:58:07]    Batch 300/365, Loss: 0.4637, Acc: 80.84%
[2025-12-02 19:58:14]    Batch 310/365, Loss: 0.8270, Acc: 80.83%
[2025-12-02 19:58:21]    Batch 320/365, Loss: 0.5739, Acc: 80.82%
[2025-12-02 19:58:27]    Batch 330/365, Loss: 0.6700, Acc: 80.79%
[2025-12-02 19:58:33]    Batch 340/365, Loss: 0.8909, Acc: 80.74%
[2025-12-02 19:58:39]    Batch 350/365, Loss: 0.7030, Acc: 80.70%
[2025-12-02 19:58:45]    Batch 360/365, Loss: 0.9848, Acc: 80.67%
[2025-12-02 19:59:42] Train Loss: 0.7578, Train Acc: 80.62%
[2025-12-02 19:59:42] Val Loss: 0.8423, Val Acc: 79.51%
[2025-12-02 19:59:42] Learning Rate: 0.001000
[2025-12-02 19:59:42] Epoch Time: 278.9s
[2025-12-02 19:59:42] 
================================================================================
[2025-12-02 19:59:42] Epoch 10/10
[2025-12-02 19:59:42] ================================================================================
[2025-12-02 19:59:48]    Batch 10/365, Loss: 0.6661, Acc: 87.81%
[2025-12-02 19:59:54]    Batch 20/365, Loss: 0.4830, Acc: 85.00%
[2025-12-02 20:00:00]    Batch 30/365, Loss: 0.9968, Acc: 83.12%
[2025-12-02 20:00:07]    Batch 40/365, Loss: 0.5231, Acc: 82.58%
[2025-12-02 20:00:13]    Batch 50/365, Loss: 0.9793, Acc: 82.19%
[2025-12-02 20:00:20]    Batch 60/365, Loss: 0.4508, Acc: 82.55%
[2025-12-02 20:00:26]    Batch 70/365, Loss: 0.9501, Acc: 82.19%
[2025-12-02 20:00:33]    Batch 80/365, Loss: 0.8233, Acc: 81.99%
[2025-12-02 20:00:38]    Batch 90/365, Loss: 0.5701, Acc: 82.57%
[2025-12-02 20:00:44]    Batch 100/365, Loss: 0.7547, Acc: 82.66%
[2025-12-02 20:00:50]    Batch 110/365, Loss: 0.7479, Acc: 82.44%
[2025-12-02 20:00:56]    Batch 120/365, Loss: 0.4246, Acc: 82.37%
[2025-12-02 20:01:02]    Batch 130/365, Loss: 0.6701, Acc: 82.14%
[2025-12-02 20:01:08]    Batch 140/365, Loss: 0.6365, Acc: 81.99%
[2025-12-02 20:01:14]    Batch 150/365, Loss: 0.5853, Acc: 82.02%
[2025-12-02 20:01:21]    Batch 160/365, Loss: 0.5697, Acc: 82.03%
[2025-12-02 20:01:28]    Batch 170/365, Loss: 0.8791, Acc: 81.71%
[2025-12-02 20:01:34]    Batch 180/365, Loss: 0.7051, Acc: 81.75%
[2025-12-02 20:01:41]    Batch 190/365, Loss: 0.8027, Acc: 81.81%
[2025-12-02 20:01:46]    Batch 200/365, Loss: 0.5664, Acc: 81.83%
[2025-12-02 20:01:52]    Batch 210/365, Loss: 0.7899, Acc: 81.71%
[2025-12-02 20:01:58]    Batch 220/365, Loss: 0.7972, Acc: 81.80%
[2025-12-02 20:02:04]    Batch 230/365, Loss: 0.8094, Acc: 81.77%
[2025-12-02 20:02:10]    Batch 240/365, Loss: 0.6742, Acc: 81.86%
[2025-12-02 20:02:16]    Batch 250/365, Loss: 0.5306, Acc: 81.99%
[2025-12-02 20:02:22]    Batch 260/365, Loss: 0.6390, Acc: 81.84%
[2025-12-02 20:02:29]    Batch 270/365, Loss: 0.8584, Acc: 81.86%
[2025-12-02 20:02:35]    Batch 280/365, Loss: 0.5737, Acc: 81.72%
[2025-12-02 20:02:41]    Batch 290/365, Loss: 0.5975, Acc: 81.78%
[2025-12-02 20:02:47]    Batch 300/365, Loss: 0.8997, Acc: 81.74%
[2025-12-02 20:02:53]    Batch 310/365, Loss: 0.6658, Acc: 81.57%
[2025-12-02 20:02:59]    Batch 320/365, Loss: 0.5671, Acc: 81.60%
[2025-12-02 20:03:05]    Batch 330/365, Loss: 0.5141, Acc: 81.55%
[2025-12-02 20:03:12]    Batch 340/365, Loss: 0.5264, Acc: 81.59%
[2025-12-02 20:03:18]    Batch 350/365, Loss: 0.4654, Acc: 81.57%
[2025-12-02 20:03:25]    Batch 360/365, Loss: 0.8512, Acc: 81.55%
[2025-12-02 20:04:22] Train Loss: 0.7198, Train Acc: 81.50%
[2025-12-02 20:04:22] Val Loss: 0.7907, Val Acc: 79.96%
[2025-12-02 20:04:22] Learning Rate: 0.001000
[2025-12-02 20:04:22] Epoch Time: 280.0s
[2025-12-02 20:04:22] 
================================================================================
[2025-12-02 20:04:22] Training complete!
[2025-12-02 20:04:22] Best validation accuracy: 80.03% (at epoch 8)
[2025-12-02 20:04:22] Model saved to: /Users/zacgarland/r_projects/agrovision/models/efficientnet_b4_houseplant_finetuned.tar
[2025-12-02 20:04:22] ================================================================================
