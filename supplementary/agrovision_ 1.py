# -*- coding: utf-8 -*-
"""AgroVision+.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lCjfetXtrgeSmoDIsIilk-TQgXkAA8yT
"""

!pip install ultralytics

from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt

# Load the YOLO model
model = YOLO('/content/yolo11x_leaf.pt')

# Run inference on an image or directory
result = model.predict('/content/2.jpeg', task="detect", save=False, conf=0.15)

# Load the original image
image_path = result[0].path
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Annotate the image with predictions
annotated_image = result[0].plot()

# Display the annotated image
plt.figure(figsize=(10, 7))
plt.imshow(annotated_image)
plt.axis("off")
plt.title(f"Predictions for Image")
plt.show()

image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
print()
leaf_images = []
for box, confid in zip(result[0].boxes, result[0].boxes.conf):
    if confid < 0.35:
        continue
    x1, y1, x2, y2 = box.xyxyn[0]
    x1, y1, x2, y2 = int(x1 * image.shape[1]), int(y1 * image.shape[0]), int(x2 * image.shape[1]), int(y2 * image.shape[0])
    cropped_image = image[y1:y2, x1:x2]
    leaf_images.append(cropped_image)
    plt.imshow(cropped_image)
    plt.axis("off")
    plt.show()

import tensorflow as tf

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from sklearn.metrics import confusion_matrix, classification_report

class Residual(tf.keras.Model):
    """The Residual block of ResNet models."""
    def __init__(self, num_channels, use_1x1conv=False, strides=1, dropout_rate=0.6):
        super().__init__()
        self.conv1 = tf.keras.layers.Conv2D(num_channels, padding='same',
                                            kernel_size=3, strides=strides)
        self.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=3,
                                            padding='same')
        self.conv3 = None
        if use_1x1conv:
            self.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=1,
                                                strides=strides)
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.bn2 = tf.keras.layers.BatchNormalization()
        self.dropout = tf.keras.layers.Dropout(dropout_rate)

    def call(self, X, training=False):
        Y = tf.keras.activations.relu(self.bn1(self.conv1(X), training=training))
        # If training=True (i.e., when the model is training), the BatchNormalization layer will compute statistics based on the current batch and normalize accordingly.
        # If training=False (i.e., during inference), it will use the running averages of the statistics learned during training.
        Y = self.bn2(self.conv2(Y), training=training)
        if self.conv3 is not None:
            X = self.conv3(X)
        Y += X
        Y = self.dropout(Y, training=training)
        # If training=True (during training), Dropout is applied. This means that random units (neurons) in the tensor Y will be set to zero with the probability defined by the dropout rate (e.g., 0.6). This prevents overfitting by forcing the model to learn more robust features without relying on any single neuron.
        # If training=False (during inference), Dropout is not applied. The output Y remains unchanged because we want the full output (no dropped units) when making predictions.
        return tf.keras.activations.relu(Y)

class ResNet(tf.keras.Model):
    def __init__(self, arch, num_classes=10, dropout_rate=0.5):
        super().__init__()
        self.b1 = tf.keras.models.Sequential([
            tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.Activation('relu'),
            tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')
        ])
        self.residual_blocks = []
        for i, (num_residuals, num_channels) in enumerate(arch):
            block = self._make_block(num_residuals, num_channels, first_block=(i == 0), dropout_rate=dropout_rate)
            self.residual_blocks.append(block)
        self.output_layer = tf.keras.models.Sequential([
            tf.keras.layers.GlobalAvgPool2D(),
            tf.keras.layers.Dense(units=num_classes, activation='softmax')
        ])

    def _make_block(self, num_residuals, num_channels, first_block=False, dropout_rate=0.5):
        blk = tf.keras.Sequential()
        for i in range(num_residuals):
            if i == 0 and not first_block:
                blk.add(Residual(num_channels, use_1x1conv=True, strides=2, dropout_rate=dropout_rate))
            else:
                blk.add(Residual(num_channels, dropout_rate=dropout_rate))
        return blk

    def call(self, X, training=False):
        X = self.b1(X, training=training)
        for block in self.residual_blocks:
            X = block(X, training=training)
        return self.output_layer(X)


# Define ResNet-18 Architecture
resnet18_arch = [(2, 64), (2, 128), (2, 256), (2, 512)]
model = ResNet(resnet18_arch, num_classes=38, dropout_rate=0.3)

import numpy as np
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.applications.imagenet_utils import preprocess_input
from PIL import Image

def preprocess_single_image(image, target_size=(224,224)):
    """
    Preprocess a single image for Keras model prediction.

    Args:
        image: PIL.Image or NumPy array (H, W, C) with pixel values 0-255
        target_size: tuple, size to resize image to

    Returns:
        Preprocessed image array with shape (1, H, W, C), ready for model.predict
    """
    # Convert NumPy array to PIL Image if needed
    if isinstance(image, np.ndarray):
        image = Image.fromarray(image.astype('uint8'))

    # Resize image
    image = image.resize(target_size)

    # Convert to array
    image_array = img_to_array(image)

    # Scale pixels to [0,1] (like rescale=1./255)
    image_array = image_array / 255.0

    # Add batch dimension
    image_array = np.expand_dims(image_array, axis=0)

    return image_array

model.build(input_shape=(None, 224, 224, 3))
model.load_weights('/content/my_resnet_model.keras')

normalized_images = []
for image in leaf_images:
  preprocessed_image = preprocess_single_image(image)
  normalized_images.append(preprocessed_image)

for img in normalized_images:
  print(img.shape)
  prediction = model.predict(np.array(img))
  print(np.argmax(prediction))

import requests

# Replace these with your values
lat = 40.7128       # latitude
lon = -74.0060      # longitude
api_key = "08bf15706db6f29d4f48aef0f07cb82c"

# API endpoint
url = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}&units=metric"

# Make the request
response = requests.get(url)

# Check if request was successful
if response.status_code == 200:
    data = response.json()
    # Example: print some weather info
    print(f"Location: {data['name']}")
    print(f"Weather: {data['weather'][0]['description']}")
    print(f"Temperature: {data['main']['temp']}°C")
    print(f"Humidity: {data['main']['humidity']}%")
else:
    print(f"Error: {response.status_code}, {response.text}")



import cv2
import numpy as np
import os
from pathlib import Path
import logging
from tqdm import tqdm

# Function to process a single image

def process_image(img):
    if img is None:
        logging.warning(f"Skipping {image_path.name} (unable to read)")
        return
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    height, width = img.shape[:2]
    margin = 0.05  # 5% margin
    x = int(width * margin)
    y = int(height * margin)
    rect = (x, y, width - 2*x, height - 2*y)

    # Create mask and models

    mask = np.zeros(img.shape[:2], np.uint8)
    bgdModel = np.zeros((1, 65), np.float64)
    fgdModel = np.zeros((1, 65), np.float64)

    # Apply GrabCut

    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)

    # Create binary mask

    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype("uint8")

    # Convert to RGBA and apply mask to alpha channel

    output_rgba = cv2.cvtColor(img, cv2.COLOR_BGR2RGBA)
    output_rgba[:, :, 3] = mask2 * 255  # 0 for background, 255 for foreground

    # output_rgba = cv2.cvtColor  (output_rgba, cv2.COLOR_RGBA2RGB)
    # Save as PNG to preserve transparency
    print(output_rgba.shape)
    plt.imshow(output_rgba)
    return output_rgba

image_segmented_4ch = process_image(leaf_images[0])



# rgba to rgb by removing mask

mask = image_segmented_4ch[:, :, 3] == 0
image_segmented_4ch[mask] = [0, 0, 0, 0]
image_segmented = image_segmented_4ch[:, :, :3]

# get all pixel in 1-D array except 0,0,0
pixels = image_segmented.reshape(-1, 3)
pixels.shape

pixels = pixels[~np.all(pixels == [0, 0, 0], axis=1)]

pixels[0]

import numpy as np
import cv2

def green_percentage_from_1d(pixels):
    """
    Calculates the percentage of green pixels in a 1D RGB pixel array.

    Args:
        pixels: NumPy array of shape (N, 3) with RGB values in [0, 255]

    Returns:
        float: percentage of green pixels
    """
    # Ensure it's a NumPy uint8 array
    pixels = np.asarray(pixels, dtype=np.uint8)

    # Remove black pixels (optional)
    pixels = pixels[~np.all(pixels == [0, 0, 0], axis=1)]
    if pixels.size == 0:
        return 0.0

    # OpenCV expects (H, W, C), BGR order
    # Reshape to (N, 1, 3) → like an image column
    pixels_bgr = pixels[:, ::-1].reshape(-1, 1, 3)

    # Convert to HSV
    hsv = cv2.cvtColor(pixels_bgr, cv2.COLOR_BGR2HSV)

    # Define HSV range for green
    lower_green = np.array([25, 30, 30], dtype=np.uint8)
    upper_green = np.array([95, 255, 255], dtype=np.uint8)

    # Create mask for green pixels
    mask = cv2.inRange(hsv, lower_green, upper_green)

    # Compute percentage
    green_percent = (np.count_nonzero(mask) / len(pixels)) * 100
    return green_percent

green = green_percentage_from_1d(pixels)

green

green_percentage = []
for limage in leaf_images:
  image_segmented_4ch = process_image(limage)
  mask = image_segmented_4ch[:, :, 3] == 0
  image_segmented_4ch[mask] = [0, 0, 0, 0]
  image_segmented = image_segmented_4ch[:, :, :3]
  pixels = image_segmented.reshape(-1, 3)
  pixels.shape
  pixels = pixels[~np.all(pixels == [0, 0, 0], axis=1)]
  green = green_percentage_from_1d(pixels)
  green_percentage.append(green)

np.mean(green_percentage)